{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Homework 4\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Wednesday, October 5th, 2016 at 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `IPython` notebook as well as the data file from Vocareum and complete locally.\n",
    "\n",
    "To submit your assignment, in Vocareum, upload (using the 'Upload' button on your Jupyter Dashboard) your solution to Vocareum as a single notebook with following file name format:\n",
    "\n",
    "`last_first_CourseNumber_HW4.ipynb`\n",
    "\n",
    "where `CourseNumber` is the course in which you're enrolled (CS 109a, Stats 121a, AC 209a). Submit your assignment in Vocareum using the 'Submit' button.\n",
    "\n",
    "**Avoid editing your file in Vocareum after uploading. If you need to make a change in a solution. Delete your old solution file from Vocareum and upload a new solution. Click submit only ONCE after verifying that you have uploaded the correct file. The assignment will CLOSE after you click the submit button.**\n",
    "\n",
    "Problems on homework assignments are equally weighted. The Challenge Question is required for AC 209A students and optional for all others. Student who complete the Challenge Problem as optional extra credit will receive +0.5% towards your final grade for each correct solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.linear_model import Ridge as Ridge_Reg\n",
    "from sklearn.linear_model import Lasso as Lasso_Reg\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import sklearn.preprocessing as Preprocessing\n",
    "import itertools as it\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "from itertools import combinations\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0: Basic Information\n",
    "\n",
    "Fill in your basic information. \n",
    "\n",
    "### Part (a): Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zhang, Christine]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Course Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CS 109a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Who did you work with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[First and Land names of students with whom you have collaborated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All data sets can be found in the ``datasets`` folder and are in comma separated value (CSV) format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Variable selection and regularization\n",
    "\n",
    "The data set for this problem is provided in ``dataset_1.txt`` and contains 10 predictors and a response variable.\n",
    "\n",
    "### Part (a): Analyze correlation among predictors\n",
    "- By visually inspecting the data set, do find that some of the predictors are correlated amongst themselves?\n",
    "\n",
    "\n",
    "- Compute the cofficient of correlation between each pair of predictors, and visualize the matrix of correlation coefficients using a heat map. Do the predictors fall naturally into groups based on the correlation values?\n",
    "\n",
    "\n",
    "- If you were asked to select a minimal subset of predictors based on the correlation information in order to build a good regression model, how many predictors will you pick, and which ones will you choose? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959357</td>\n",
       "      <td>0.959357</td>\n",
       "      <td>0.959357</td>\n",
       "      <td>0.343727</td>\n",
       "      <td>0.524083</td>\n",
       "      <td>0.537768</td>\n",
       "      <td>0.435598</td>\n",
       "      <td>0.831999</td>\n",
       "      <td>0.153247</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.289394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.287376</td>\n",
       "      <td>0.513844</td>\n",
       "      <td>0.497775</td>\n",
       "      <td>0.452732</td>\n",
       "      <td>0.914609</td>\n",
       "      <td>0.367390</td>\n",
       "      <td>0.444473</td>\n",
       "      <td>-0.277574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995941</td>\n",
       "      <td>0.995941</td>\n",
       "      <td>0.995941</td>\n",
       "      <td>0.107294</td>\n",
       "      <td>0.097106</td>\n",
       "      <td>0.146751</td>\n",
       "      <td>0.136414</td>\n",
       "      <td>0.635926</td>\n",
       "      <td>0.535209</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>-0.513097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821732</td>\n",
       "      <td>0.821732</td>\n",
       "      <td>0.821732</td>\n",
       "      <td>0.202558</td>\n",
       "      <td>0.329504</td>\n",
       "      <td>0.359471</td>\n",
       "      <td>0.281453</td>\n",
       "      <td>0.106263</td>\n",
       "      <td>0.479327</td>\n",
       "      <td>0.256271</td>\n",
       "      <td>-0.182353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302423</td>\n",
       "      <td>0.302423</td>\n",
       "      <td>0.302423</td>\n",
       "      <td>0.184564</td>\n",
       "      <td>0.270263</td>\n",
       "      <td>0.293385</td>\n",
       "      <td>0.263866</td>\n",
       "      <td>0.378630</td>\n",
       "      <td>0.740241</td>\n",
       "      <td>0.468589</td>\n",
       "      <td>-0.625117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.037635</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>0.337794</td>\n",
       "      <td>0.615117</td>\n",
       "      <td>0.567644</td>\n",
       "      <td>0.589955</td>\n",
       "      <td>0.648310</td>\n",
       "      <td>0.061586</td>\n",
       "      <td>0.561851</td>\n",
       "      <td>-0.025617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.548117</td>\n",
       "      <td>0.116262</td>\n",
       "      <td>0.113592</td>\n",
       "      <td>0.087629</td>\n",
       "      <td>0.111386</td>\n",
       "      <td>0.928244</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.221628</td>\n",
       "      <td>0.297171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.892827</td>\n",
       "      <td>0.892827</td>\n",
       "      <td>0.892827</td>\n",
       "      <td>0.281551</td>\n",
       "      <td>0.416681</td>\n",
       "      <td>0.348842</td>\n",
       "      <td>0.351801</td>\n",
       "      <td>0.594220</td>\n",
       "      <td>0.712219</td>\n",
       "      <td>0.885876</td>\n",
       "      <td>-0.370487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.742638</td>\n",
       "      <td>0.742638</td>\n",
       "      <td>0.742638</td>\n",
       "      <td>0.346271</td>\n",
       "      <td>0.501471</td>\n",
       "      <td>0.461488</td>\n",
       "      <td>0.473039</td>\n",
       "      <td>0.154119</td>\n",
       "      <td>0.754183</td>\n",
       "      <td>0.615930</td>\n",
       "      <td>-0.580507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.019027</td>\n",
       "      <td>0.019027</td>\n",
       "      <td>0.019027</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.092674</td>\n",
       "      <td>0.077819</td>\n",
       "      <td>0.094770</td>\n",
       "      <td>0.295878</td>\n",
       "      <td>0.705932</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>-0.415906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.959357  0.959357  0.959357  0.343727  0.524083  0.537768  0.435598   \n",
       "1  0.616969  0.616969  0.616969  0.287376  0.513844  0.497775  0.452732   \n",
       "2  0.995941  0.995941  0.995941  0.107294  0.097106  0.146751  0.136414   \n",
       "3  0.821732  0.821732  0.821732  0.202558  0.329504  0.359471  0.281453   \n",
       "4  0.302423  0.302423  0.302423  0.184564  0.270263  0.293385  0.263866   \n",
       "5  0.037635  0.037635  0.037635  0.337794  0.615117  0.567644  0.589955   \n",
       "6  0.548117  0.548117  0.548117  0.116262  0.113592  0.087629  0.111386   \n",
       "7  0.892827  0.892827  0.892827  0.281551  0.416681  0.348842  0.351801   \n",
       "8  0.742638  0.742638  0.742638  0.346271  0.501471  0.461488  0.473039   \n",
       "9  0.019027  0.019027  0.019027  0.090675  0.092674  0.077819  0.094770   \n",
       "\n",
       "         7         8         9         10  \n",
       "0  0.831999  0.153247  0.005016  0.289394  \n",
       "1  0.914609  0.367390  0.444473 -0.277574  \n",
       "2  0.635926  0.535209  0.899457 -0.513097  \n",
       "3  0.106263  0.479327  0.256271 -0.182353  \n",
       "4  0.378630  0.740241  0.468589 -0.625117  \n",
       "5  0.648310  0.061586  0.561851 -0.025617  \n",
       "6  0.928244  0.121747  0.221628  0.297171  \n",
       "7  0.594220  0.712219  0.885876 -0.370487  \n",
       "8  0.154119  0.754183  0.615930 -0.580507  \n",
       "9  0.295878  0.705932  0.865741 -0.415906  "
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.loadtxt('datasets/dataset_1.txt', delimiter=',', skiprows=1)\n",
    "\n",
    "# Split predictors and response\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head(n = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAF6CAYAAAAJaaMjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgy6JDXx/wEhGltPg0jMVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bedc510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute matrix of correlation coefficients\n",
    "corr_matrix = np.corrcoef(x.T)\n",
    "\n",
    "# Display heat map \n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "ax.pcolor(corr_matrix)\n",
    "\n",
    "ax.set_title('Heatmap of correlation matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the correlation variables naturally fall into groups. The natural segmentations are 0 - 2, 3 - 6, 7, 8, and 9. Thus, if I were to pick predictors, I would choose a minimum of 5 predictors because I want at least one from all 5 of the segmentations. These predictors would include 7, 8, 9, one from 0 - 2, and one from 3 - 6. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Selecting minimal subset of predictors\n",
    "\n",
    "- Apply the variable selection methods discussed in class to choose a minimal subset of predictors that yield high prediction accuracy:\n",
    "    \n",
    "    - Exhaustive search\n",
    "    \n",
    "    - Step-wise forward selection **or** Step-wise backward selection  \n",
    "\n",
    "&emsp;&nbsp;&nbsp; In each method, use the Bayesian Information Criterion (BIC) to choose the subset size.\n",
    "\n",
    "- Do the chosen subsets match the ones you picked using the correlation matrix you had visualized in Part (a)?\n",
    "\n",
    "**Note**: You may use the `statsmodels`'s `OLS` module to fit a linear regression model and evaluate BIC. You may **not** use library functions that implement variable selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subset by exhaustive search:\n",
      "[0, 5, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Best Subset Selection\n",
    "min_bic = 1e10 # set some initial large value for min BIC score\n",
    "best_subset = [] # best subset of predictors\n",
    "\n",
    "# Create all possible subsets of the set of 10 predictors\n",
    "predictor_set = set(range(10)) # predictor set = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
    "\n",
    "# Repeat for every possible size of subset\n",
    "for size_k in range(10): \n",
    "    # Create all possible subsets of size 'size', \n",
    "    # using the 'combination' function from the 'itertools' library\n",
    "    subsets_of_size_k = it.combinations(predictor_set, size_k + 1) \n",
    "    \n",
    "    max_r_squared = -1e10 # set some initial small value for max R^2 score\n",
    "    best_k_subset = [] # best subset of predictors of size k\n",
    "    \n",
    "    # Iterate over all subsets of our predictor set\n",
    "    for predictor_subset in subsets_of_size_k:    \n",
    "        # Use only a subset of predictors in the training data\n",
    "        x_subset = x[:, predictor_subset]\n",
    "\n",
    "        # Fit and evaluate R^2\n",
    "        model = OLS(y, x_subset)\n",
    "        results = model.fit()\n",
    "        r_squared = results.rsquared\n",
    "        \n",
    "        # Update max R^2 and best predictor subset of size k\n",
    "        # If current predictor subset has a higher R^2 score than that of the best subset \n",
    "        # we've found so far, remember the current predictor subset as the best!\n",
    "        if(r_squared > max_r_squared): \n",
    "            max_r_squared = r_squared\n",
    "            best_k_subset = predictor_subset[:]\n",
    "                \n",
    "\n",
    "    # Use only the best subset of size k for the predictors\n",
    "    x_subset = x[:, best_k_subset]\n",
    "        \n",
    "    # Fit and evaluate BIC of the best subset of size k\n",
    "    model = OLS(y, x_subset)\n",
    "    results = model.fit()\n",
    "    bic = results.bic\n",
    "    \n",
    "    # Update minimum BIC and best predictor subset\n",
    "    # If current predictor has a lower BIC score than that of the best subset \n",
    "    # we've found so far, remember the current predictor as the best!\n",
    "    if(bic < min_bic): \n",
    "        min_bic = bic\n",
    "        best_subset = best_k_subset[:]\n",
    "    \n",
    "print('Best subset by exhaustive search:')\n",
    "print sorted(best_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-wise forward subset selection:\n",
      "[0, 5, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "### Step-wise Forward Selection\n",
    "d = x.shape[1] # total no. of predictors\n",
    "\n",
    "# Keep track of current set of chosen predictors, and the remaining set of predictors\n",
    "current_predictors = [] \n",
    "remaining_predictors = range(d)\n",
    "\n",
    "# Set some initial large value for min BIC score for all possible subsets\n",
    "global_min_bic = 1e10 \n",
    "\n",
    "# Keep track of the best subset of predictors\n",
    "best_subset = [] \n",
    "\n",
    "# Iterate over all possible subset sizes, 0 predictors to d predictors\n",
    "for size in range(d):    \n",
    "    max_r_squared = -1e10 # set some initial small value for max R^2\n",
    "    best_predictor = -1 # set some throwaway initial number for the best predictor to add\n",
    "    bic_with_best_predictor = 1e10 # set some initial large value for BIC score   \n",
    "        \n",
    "    # Iterate over all remaining predictors to find best predictor to add\n",
    "    for i in remaining_predictors:\n",
    "        # Make copy of current set of predictors\n",
    "        temp = current_predictors[:]\n",
    "        # Add predictor 'i'\n",
    "        temp.append(i)\n",
    "                                    \n",
    "        # Use only a subset of predictors in the training data\n",
    "        x_subset = x[:, temp]\n",
    "        \n",
    "        # Fit and evaluate R^2\n",
    "        model = OLS(y, x_subset)\n",
    "        results = model.fit()\n",
    "        r_squared = results.rsquared\n",
    "        \n",
    "        # Check if we get a higher R^2 value than than current max R^2, if so, update\n",
    "        if(r_squared > max_r_squared):\n",
    "            max_r_squared = r_squared\n",
    "            best_predictor = i\n",
    "            bic_with_best_predictor = results.bic\n",
    "    \n",
    "    # Remove best predictor from remaining list, and add best predictor to current list\n",
    "    remaining_predictors.remove(best_predictor)\n",
    "    current_predictors.append(best_predictor)\n",
    "    \n",
    "    # Check if BIC for with the predictor we just added is lower than \n",
    "    # the global minimum across all subset of predictors\n",
    "    if(bic_with_best_predictor < global_min_bic):\n",
    "        best_subset = current_predictors[:]\n",
    "        global_min_bic = bic_with_best_predictor\n",
    "    \n",
    "print 'Step-wise forward subset selection:'\n",
    "print sorted(best_subset) # add 1 as indices start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-wise backward subset selection:\n",
      "[2, 5, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "###  Step-wise Backward Selection\n",
    "d = x.shape[1] # total no. of predictors\n",
    "\n",
    "# Keep track of current set of chosen predictors\n",
    "current_predictors = range(d)\n",
    "\n",
    "# First, fit and evaluate BIC using all 'd' number of predictors\n",
    "model = OLS(y, x)\n",
    "results = model.fit()\n",
    "bic_all = results.bic\n",
    "\n",
    "# Set the minimum BIC score, initially, to the BIC score using all 'd' predictors\n",
    "global_min_bic = bic_all\n",
    "# Keep track of the best subset of predictors\n",
    "best_subset = [] \n",
    "\n",
    "# Iterate over all possible subset sizes, d predictors to 1 predictor\n",
    "for size in range(d - 1, 1, -1): # stop before 0 to avoid choosing an empty set of predictors\n",
    "    max_r_squared = -1e10 # set some initial small value for max R^2\n",
    "    worst_predictor = -1 # set some throwaway initial number for the worst predictor to remove\n",
    "    bic_without_worst_predictor = 1e10 # set some initial large value for min BIC score  \n",
    "        \n",
    "    # Iterate over current set of predictors (for potential elimination)\n",
    "    for i in current_predictors:\n",
    "        # Create copy of current predictors, and remove predictor 'i'\n",
    "        temp = current_predictors[:]\n",
    "        temp.remove(i)\n",
    "                                    \n",
    "        # Use only a subset of predictors in the training data\n",
    "        x_subset = x[:, temp]\n",
    "        \n",
    "        # Fit and evaluate R^2\n",
    "        model = OLS(y, x_subset)\n",
    "        results = model.fit()\n",
    "        r_squared = results.rsquared\n",
    "        \n",
    "        # Check if we get a higher R^2 value than than current max R^2, if so, update\n",
    "        if(r_squared > max_r_squared):\n",
    "            max_r_squared = r_squared\n",
    "            worst_predictor = i\n",
    "            bic_without_worst_predictor = results.bic\n",
    "          \n",
    "    # Remove worst predictor from current set of predictors\n",
    "    current_predictors.remove(worst_predictor)\n",
    "    \n",
    "    # Check if BIC for the predictor we just removed is lower than \n",
    "    # the global minimum across all subset of predictors\n",
    "    if(bic_without_worst_predictor < global_min_bic):\n",
    "        best_subset = current_predictors[:]\n",
    "        global_min_bic = bic_without_worst_predictor\n",
    "    \n",
    "print 'Step-wise backward subset selection:'\n",
    "print sorted(best_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen subsets match the predictors suggested by the correlation matrix. We predicted a minimum of 5 predictors including 7, 8, and 9. The remaining two predictors came from 1 within 0 - 2 and 1 within 3 - 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Apply Lasso and Ridge regression\n",
    "\n",
    "- Apply Lasso regression with regularization parameter $\\lambda = 0.01$ and fit a regression model.\n",
    "\n",
    "    - Identify the predictors that are assigned non-zero coefficients. Do these correspond to  the correlation matrix in Part (a)?\n",
    "\n",
    "\n",
    "- Apply Ridge regression with regularization parameter $\\lambda = 0.01$ and fit a regression model.\n",
    "\n",
    "    - Is there a difference between the model parameters you obtain different and those obtained from Lasso regression? If so, explain why.\n",
    "\n",
    "    - Identify the predictors that are assigned non-zero coefficients. Do these correspond to  the correlation matrix in Part (a)?\n",
    "\n",
    "\n",
    "- Is there anything peculiar that you observe about the coefficients Ridge regression assigns to the first three predictors? Do you observe the same with Lasso regression? Give an explanation for your observation.\n",
    "\n",
    "**Note**: You may use the `statsmodels` or `sklearn` to perform Lasso and Ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso:\n",
      "Coefficients: [ 0.02717417  0.          0.         -0.         -0.02532806 -0.         -0.\n",
      "  0.04397321 -0.40612185 -0.22260474]\n",
      "Predictors with non-zero coefficients: [0, 4, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression\n",
    "reg = Lasso_Reg(alpha = 0.01)\n",
    "reg.fit(x, y)\n",
    "coefficients = reg.coef_\n",
    "\n",
    "print 'Lasso:'\n",
    "print 'Coefficients:', coefficients\n",
    "print  'Predictors with non-zero coefficients:', [i for i, item in enumerate(coefficients) if abs(item) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, these parameters correspond to the correlation matrix. According to the coorelation matrix, we need to have a minimum of 5 paramters including 7, 8, 9, 1 of 0-2, and 1 of 3-6. The Lasso results give us 5 non-zero coefficients: [0, 4, 7, 8, 9]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge:\n",
      "Coefficients: [ 0.04353543  0.04353543  0.04353543  0.55217415 -0.19706852 -0.61421737\n",
      "  0.30484213  0.18742866 -0.50083242 -0.35908145]\n",
      "Predictors with non-zero coefficients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Ridge regression: Fit and evaluate \n",
    "reg = Ridge_Reg(alpha = 0.01)\n",
    "x[:,1] = x[:,0]\n",
    "x[:,2] = x[:,0]\n",
    "reg.fit(x, y)\n",
    "coefficients = reg.coef_\n",
    "\n",
    "print 'Ridge:'\n",
    "print 'Coefficients:', coefficients\n",
    "print 'Predictors with non-zero coefficients:', [i for i, item in enumerate(coefficients) if abs(item) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ridge parameters are very different from the Lasso parameters because none are zero. All of the coefficients are non-zero and therefore, do not correspond as well with the correlation matrix, which tells us that only 5 cofficients are necessary to form a good prediction. The Ridge regression does not zero out coefficients unless lambda equals infinity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients Ridge regression assigns to the first three predictors are all small and the same value (0.0435). In Lasso, two of the three predictors are zero and the third is a small, positive number. This is because, unlike Lasso, Ridge does not send values to zero unless lambda approaches infinity. Since 0 - 2 are all very tightly correlated with each other, Ridge will minimize all of these values equally since they are poor predictors. We do not observe the same with Lasso since Lasso sends values to 0 if they are not good predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Cross-validation and Bootstrapping\n",
    "In this problem, you will work with an expanded version of the automobile pricing data set you analyzed in Homework 3. The data set is contained ``dataset_2.txt``, with 26 attribues (i.e. predictors) for each automobile and corresponding prices. \n",
    "\n",
    "### Part(a): Encode categorical attributes and fill missing values\n",
    "Identify the categorical attributes in the data. Replace their values with the one-hot binary encoding. You may do this using the `get_dummies()` function in `pandas`. If you do this task correctly, you should get a total of 69 predictors after the encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horsepower</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-type</th>\n",
       "      <th>num-of-cylinders</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.232558</td>\n",
       "      <td>peugot</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>four</td>\n",
       "      <td>120.0</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2.19</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>toyota</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hardtop</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>146.0</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>bmw</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>ohc</td>\n",
       "      <td>six</td>\n",
       "      <td>164.0</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.232558</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>ohcv</td>\n",
       "      <td>eight</td>\n",
       "      <td>308.0</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>subaru</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>...</td>\n",
       "      <td>ohcf</td>\n",
       "      <td>four</td>\n",
       "      <td>108.0</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.64</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>...</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.11</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>peugot</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>four</td>\n",
       "      <td>120.0</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.19</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>140.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>...</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>131.0</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>86.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>honda</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>...</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1bbl</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.58</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>69.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>nissan</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>...</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.29</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5499.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   horsepower  highway-mpg  symboling  normalized-losses           make  \\\n",
       "0        95.0         24.0        0.0         120.232558         peugot   \n",
       "1       116.0         30.0        2.0         134.000000         toyota   \n",
       "2       121.0         28.0        0.0         188.000000            bmw   \n",
       "3       184.0         16.0        0.0         120.232558  mercedes-benz   \n",
       "4       111.0         29.0        0.0         102.000000         subaru   \n",
       "5        70.0         43.0        0.0          81.000000      chevrolet   \n",
       "6        97.0         24.0        0.0         161.000000         peugot   \n",
       "7       140.0         20.0        1.0         158.000000           audi   \n",
       "8        86.0         33.0        0.0          85.000000          honda   \n",
       "9        69.0         37.0        1.0         128.000000         nissan   \n",
       "\n",
       "  fuel-type aspiration num-of-doors body-style drive-wheels   ...     \\\n",
       "0       gas        std         four      wagon          rwd   ...      \n",
       "1       gas        std          two    hardtop          rwd   ...      \n",
       "2       gas        std          two      sedan          rwd   ...      \n",
       "3       gas        std         four      sedan          rwd   ...      \n",
       "4       gas      turbo         four      sedan          4wd   ...      \n",
       "5       gas        std         four      sedan          fwd   ...      \n",
       "6       gas        std         four      sedan          rwd   ...      \n",
       "7       gas      turbo         four      sedan          fwd   ...      \n",
       "8       gas        std         four      sedan          fwd   ...      \n",
       "9       gas        std          two      sedan          fwd   ...      \n",
       "\n",
       "  engine-type  num-of-cylinders  engine-size  fuel-system  bore  stroke  \\\n",
       "0           l              four        120.0         mpfi  3.46    2.19   \n",
       "1         ohc              four        146.0         mpfi  3.62    3.50   \n",
       "2         ohc               six        164.0         mpfi  3.31    3.19   \n",
       "3        ohcv             eight        308.0         mpfi  3.80    3.35   \n",
       "4        ohcf              four        108.0         mpfi  3.62    2.64   \n",
       "5         ohc              four         90.0         2bbl  3.03    3.11   \n",
       "6           l              four        120.0         mpfi  3.46    3.19   \n",
       "7         ohc              five        131.0         mpfi  3.13    3.40   \n",
       "8         ohc              four        110.0         1bbl  3.15    3.58   \n",
       "9         ohc              four         97.0         2bbl  3.15    3.29   \n",
       "\n",
       "  compression-ratio peak-rpm  city-mpg    price  \n",
       "0               8.4   5000.0      19.0  16695.0  \n",
       "1               9.3   4800.0      24.0  11199.0  \n",
       "2               9.0   4250.0      21.0  20970.0  \n",
       "3               8.0   4500.0      14.0  40960.0  \n",
       "4               7.7   4800.0      24.0  11259.0  \n",
       "5               9.6   5400.0      38.0   6575.0  \n",
       "6               8.4   5000.0      19.0  11900.0  \n",
       "7               8.3   5500.0      17.0  23875.0  \n",
       "8               9.0   5800.0      27.0   8845.0  \n",
       "9               9.4   5200.0      31.0   5499.0  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data_pd = pd.read_csv('datasets/dataset_2.txt')\n",
    "data_np = data_pd.as_matrix()\n",
    "\n",
    "# Split predictors and response\n",
    "x = data_np[:, :-1]\n",
    "y = data_np[:, -1]\n",
    "\n",
    "data_pd.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate out categorical variables from quantitative variables\n",
    "data_1 = data_pd.iloc[:, 0:2]\n",
    "data_2 = data_pd.iloc[:, 2]\n",
    "\n",
    "# Use get_dummies to break down categorical variables into their own columns\n",
    "data_2_dummies = pd.get_dummies(data_2)\n",
    "data_3 = data_pd.iloc[:, 3]\n",
    "data_4 = data_pd.iloc[:, 4:11]\n",
    "data_4_dummies = pd.get_dummies(data_4)\n",
    "data_5 = data_pd.iloc[:, 11:16]\n",
    "data_6 = data_pd.iloc[:, 16:18]\n",
    "data_6_dummies = pd.get_dummies(data_6)\n",
    "data_7 = data_pd.iloc[:, 18]\n",
    "data_8 = data_pd.iloc[:, 19]\n",
    "data_8_dummies = pd.get_dummies(data_8)\n",
    "data_9 = data_pd.iloc[:, 20:]\n",
    "\n",
    "# Concatenate all of the data slices together\n",
    "data_concat = pd.concat([data_1, data_2_dummies, data_3, data_4_dummies, data_5, data_6_dummies, data_7, data_8_dummies, data_9], axis = 1)\n",
    "\n",
    "# Remove the last column, which is the response variable, to just have the predictors\n",
    "data_final =data_concat.iloc[:, 0:69]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Apply regular linear regression\n",
    "- Split the data set into train and test sets, with the first 25% of the data for training and the remaining for testing.  \n",
    "\n",
    "\n",
    "- Use regular linear regression to fit a model to the training set and evaluate the R^2 score of the fitted model on both the training and test sets. What do you observe about these values?\n",
    "\n",
    "\n",
    "- You had seen in class that the R^2 value of a least-squares fit to a data set would lie between 0 and 1. Is this true for the test R^2 values reported above? If not, give a reason for why this is the case.\n",
    "\n",
    "\n",
    "- Is there a need for regularization while fitting a linear model to this data set?\n",
    "\n",
    "**Note**: You may use the `statsmodels` or `sklearn` to fit a linear regression model and evaluate the fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Test R Squared Value:  -5.97542556681\n",
      "Linear Regression Train R Squared Value:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Divide out the data into training and testing sets for predictors and response variables\n",
    "data_cols = data_concat.columns\n",
    "x_train = data_final.iloc[0:51]\n",
    "x_test = data_final.iloc[51:]\n",
    "y_train = data_concat['price'].iloc[0:51]\n",
    "y_test = data_concat['price'].iloc[51:]\n",
    "\n",
    "# Use a linear regression fit \n",
    "reg = Lin_Reg()\n",
    "reg.fit(x_train, y_train)\n",
    "coefficients = reg.coef_\n",
    "\n",
    "# Calculate r squared values of testing and training sets\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "test = reg.score(x_test, y_test)\n",
    "train = reg.score(x_train, y_train)\n",
    "    \n",
    "print \"Linear Regression Test R Squared Value: \", test\n",
    "print \"Linear Regression Train R Squared Value: \", train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R squared for the training set is 1.0. This means that it is a perfect prediction and usually an indication of overfitting. Since the training dat set is so small, we see that it is a poor dataset for determining the model. This is evident in the negative test r squared value of -5.975. \n",
    "\n",
    "The R squared values are problematic here because of the categorical variables, which take on values 0.0 and 1.0 but are meaningless since they are dummy variables used as placeholders. This can explain for why the R squared value is not in between 0 and 1. Therefore, we will need regularization while fitting this data set to bring the R squared testing value between 0 and 1, turning it into a number we can interpret. The regularization parameter can also shrink factors that aren't true predictors so we do not have extraneous variables overfitting the dataset or skewing the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Apply Ridge regression\n",
    "\n",
    "- Apply Ridge regression on the training set for different values of the regularization parameter $\\lambda$ in the range $\\{10^{-7}, 10^{-6}, \\ldots, 10^7\\}$. Evaluate the R^2 score for the models you obtain on both the train and test sets. Plot both values as a function of $\\lambda$. \n",
    "\n",
    "\n",
    "- Explain the relationship between the regularization parameter and the training and test R^2 scores.\n",
    "\n",
    "\n",
    "- How does the best test R^2 value obtained using Ridge regression compare with that of plain linear regression? Explain.\n",
    "\n",
    "**Note**: You may use the `statsmodels` or `sklearn` to fit a ridge regression model and evaluate the fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEPCAYAAABP1MOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a5ade50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ridge regression: Fit and evaluate \n",
    "lambda_array = []\n",
    "r_squared_testing = []\n",
    "r_squared_training = []\n",
    "for i in range(-7, 8):\n",
    "    lambda_array.append(10**i)\n",
    "\n",
    "# Iterate through lambda_array to test all values\n",
    "for m in lambda_array:\n",
    "    reg = Ridge_Reg(alpha = m)\n",
    "    \n",
    "    # Conduct ridge regression on testing data\n",
    "    reg.fit(x_train, y_train)\n",
    "    r_squared_testing.append(reg.score(x_test, y_test))\n",
    "    \n",
    "    # Conduct ridge regression on training data\n",
    "    reg.fit(x_train, y_train)\n",
    "    r_squared_training.append(reg.score(x_train, y_train))\n",
    "\n",
    "# Plot testing and training data for the ridge regression\n",
    "plt.plot(range(-7,8), r_squared_testing, label = 'test')\n",
    "plt.plot(range(-7,8), r_squared_training, label = 'train')\n",
    "plt.xlabel('Lambda'); \n",
    "plt.ylim([-6,2])\n",
    "plt.ylabel('R Squared Values')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max r squared of ridge regression test data:  0.913535120275\n"
     ]
    }
   ],
   "source": [
    "print \"Max r squared of ridge regression test data: \", np.max(r_squared_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the regularization parameter increases, we see that the r squared of test data increases from - 6 to ~0.5 as lambda increases while the r squared of training data remains constant around 1 with a slight decreasing slope. The best test r squared data from plain linear regression is -5.9754 while the best test r squared data from ridge regression is 0.9135. This shows how regularization was able to develop a better model. With a larger lambda, we were able to more heavily penalize poor predictors, removing the impact of cofounding variables and ending up with a more accurate model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d): Tune regularization parameter using cross-validation and bootstrapping\n",
    "-  Evaluate the performance of the Ridge regression for different regularization parameters $\\lambda$ using 5-fold cross validation **or** bootstrapping on the training set. \n",
    "\n",
    "    - Plot the cross-validation (CV) or bootstrapping R^2 score as a function of $\\lambda$. \n",
    "    \n",
    "    - How closely does the CV score or bootstrapping score match the R^2 score on the test set? Does the model with lowest CV score or bootstrapping score correspond to the one with maximum R^2 on the test set?\n",
    "    \n",
    "    - Does the model chosen by CV or bootstrapping perform better than plain linear regression?\n",
    "\n",
    "**Note**: You may use the `statsmodels` or `sklearn` to fit a linear regression model and evaluate the fits. You may also use `kFold` from `sklearn.cross_validation`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAGDCAYAAAAxhIflAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREJSgRARkZBUIEREJKT/D8+zexNNWxosAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c1b6c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# initalize empty matrices\n",
    "r_squared_train, r_squared_test, lambda_array = [], [], []\n",
    "\n",
    "# Conduct 5-fold cross validation\n",
    "kf = KFold(x_train.shape[0], n_folds = 5)\n",
    "\n",
    "# create array of lambdas\n",
    "for i in range(-7, 8):\n",
    "    lambda_array.append(10 ** i)\n",
    "\n",
    "# conduct ridge regression for a variety of lambdas\n",
    "for m in lambda_array:\n",
    "    r_squared_train_cv = 0\n",
    "    r_squared_test_cv = 0\n",
    "    \n",
    "    # Conduct ridge regression on a given lambda\n",
    "    reg = Ridge_Reg(alpha = m)\n",
    "    x_train_np = x_train.as_matrix()\n",
    "    x_test_np = x_test.as_matrix()\n",
    "    y_test_np = y_test.as_matrix()\n",
    "    y_train_np = y_train.as_matrix()\n",
    "    \n",
    "    # Iterate through each fold and calculate r squared values for each\n",
    "    for train_idx, test_idx in kf:\n",
    "        reg.fit(x_train_np[train_idx], y_train[train_idx])\n",
    "        r_squared_train_cv += reg.score(x_train_np[train_idx], y_train[train_idx])\n",
    "        r_squared_test_cv += reg.score(x_test_np[test_idx], y_test_np[test_idx])\n",
    "    r_squared_train.append(r_squared_train_cv/5)\n",
    "    r_squared_test.append(r_squared_test_cv/5)\n",
    "        \n",
    "# Graph to find best lambda and then plug into ridge_reg to calculate r squared value\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "\n",
    "# Plot on a semilog plot\n",
    "ax.semilogx(10.0**np.arange(-7, 8), r_squared_train, label='train kfold')\n",
    "ax.semilogx(10.0**np.arange(-7, 8), r_squared_test, label='test kfold')\n",
    "ax.semilogx(10.0**np.arange(-7, 8), r_squared_testing, label='test ridge')\n",
    "\n",
    "# Annotate the graph for clarity \n",
    "plt.xlabel('Lambda'); \n",
    "plt.ylim([-6, 3])\n",
    "plt.ylabel('R Squared Values')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of max r squared value:  4\n"
     ]
    }
   ],
   "source": [
    "# Find the index that gives us the maximum r squared value\n",
    "print \"Value of max r squared value: \", np.argmax(r_squared_test) - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared value of test data:  0.854146105699\n"
     ]
    }
   ],
   "source": [
    "reg = Ridge_Reg(alpha = 10 ** -2)\n",
    "reg.fit(x_train, y_train)\n",
    "print \"R squared value of test data: \", reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As lambda increases, the CV score increases from -5 to ~0.5. The CV score very closely matches the R^2 score of the test set. We can see this in the graph as the two lines take on similiar shapes. The model with the lowest CV score does not correspond to the one with maximum R^2 on the test set. Since we analyzing R squared values, we should be maximizing CV and looking at that index value instead. \n",
    "\n",
    "The maximum R^2 value is 0.858, which corresponds to the R^2 obtained from ridge regression above of 0.913. The R^2 obtained by linear regression was -5.975. Thus, it is evident that the model chosen by CV performs significantly better than linear regression alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Ridge regression *via* ordinary least-squares regression\n",
    "\n",
    "We present an approach to implement Ridge regression using oridinary least-squares regression. Given a matrix of responses $\\mathbf{X} \\in \\mathbb{R}^{n\\times p}$ and response vector $\\mathbf{y} \\in \\mathbb{R}^{n}$, one can implement Ridge regression with regularization parameter $\\lambda$ as follows:\n",
    "\n",
    "- Augment the matrix of predictors $\\mathbf{X}$ with $p$ new rows containing the scaled identity matrix $\\sqrt{\\lambda}\\mathbf{I} \\in \\mathbb{R}^{p \\times p}$, i.e.\n",
    "$$\\overline{\\mathbf{X}} \\,=\\, \n",
    "\\begin{bmatrix}\n",
    "X_{11} & \\ldots & X_{1p}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "X_{n1} & \\ldots & X_{np}\\\\\n",
    "\\sqrt{\\lambda} & \\ldots & 0\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "0 & \\ldots & \\sqrt{\\lambda}\n",
    "\\end{bmatrix}\n",
    "\\,\\in\\,\n",
    "\\mathbb{R}^{(n+p)\\times p}\n",
    ".\n",
    "$$\n",
    "\n",
    "\n",
    "- Augment the response vector $\\mathbf{y}$ with a column of $p$ zeros, i.e.\n",
    "$$\n",
    "\\overline{\\mathbf{y}} \\,=\\, \n",
    "\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n}\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\,\\in\\,\n",
    "\\mathbb{R}^{n+p}.\n",
    "$$\n",
    "\n",
    "\n",
    "- Apply ordinary least-squares regression on the augmented data set $(\\overline{\\mathbf{X}}, \\overline{\\mathbf{y}})$.\n",
    "\n",
    "### Part (a): Show the proposed approach implements Ridge regression\n",
    "Show that the approach proposed above implements Ridge regression with parameter $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSS: $$ RSS = \\sum_{i=1}^{n}\\left(y_i - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2 $$\n",
    "\n",
    "Ridge Regression with Parameter $\\lambda$: $$ \\sum_{i=1}^{n}\\left(y_i - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2  + \\lambda \\sum_{j=1}^{p} \\beta_k^2 = RSS + \\lambda \\sum_{j=1}^{p} \\beta_k^2 $$\n",
    "\n",
    "\n",
    "OLS measures the vertical distance between observed data and the expected value. \n",
    "$$S(b) =\\sum _{i=1}^{n}(y_{i}-x_{i}^{T}b)^{2}=(y-Xb)^{T}(y-Xb)$$\n",
    "\n",
    "A vector multipled by its own transpose is equivalent to taking the dot product.\n",
    "\n",
    "$$(y-Xb)^{T}(y-Xb) = (y - Xb) \\cdot (y-Xb) $$\n",
    "\n",
    "\n",
    "$$(y-Xb)=\n",
    "\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n}\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "-\n",
    "\\begin{bmatrix}\n",
    "X_{11} & \\ldots & X_{1p}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "X_{n1} & \\ldots & X_{np}\\\\\n",
    "\\sqrt{\\lambda} & \\ldots & 0\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "0 & \\ldots & \\sqrt{\\lambda}\n",
    "\\end{bmatrix}\n",
    "*\n",
    "\\begin{bmatrix}\n",
    "\\beta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_{n}\\\\\n",
    "\\beta_{n+1}\\\\\n",
    "\\vdots \\\\\n",
    "\\beta_{p}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$(y-Xb)=\n",
    "\\begin{bmatrix}\n",
    "y_{1} - x_{11}*\\beta_1 &\\ldots -x_{1p}*\\beta_{p}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n} - x_{n1}*\\beta_{1} &\\ldots -x_{np}*\\beta_{p} \\\\\n",
    "-\\sqrt{\\lambda} * \\beta_{1} &\\ldots -\\sqrt{\\lambda}*\\beta_{p}\\\\\n",
    "\\vdots\\\\\n",
    "-\\sqrt{\\lambda} * \\beta_{p} &\\ldots -\\sqrt{\\lambda}*\\beta_{p}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Thus, if we take the dot product, which is the sum of the square of each term, the y terms and x * beta terms produce the RSS. \n",
    "$$ \\sum_{i=1}^{n}\\left(y_i - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2 $$\n",
    "\n",
    "The remaining squared lambda * beta terms produce: \n",
    "$$\\lambda \\sum_{j=1}^{p} \\beta_k^2 $$\n",
    "\n",
    "Combinded, these matrices represent Ridge regression. \n",
    "$$ \\sum_{i=1}^{n}\\left(y_i - \\sum_{j=1}^{p} \\beta_j x_{ij} \\right)^2  + \\lambda \\sum_{j=1}^{p} \\beta_k^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Debug our implementation of ridge regression\n",
    "You're a grader for CS109A, the following is an implemention of Ridge regression (via the above approach) submitted by a student. The dataset is ``dataset_3.txt``. The regression model is fitted to a training set, and the R^2 scores of the fitted model on the training and test sets are plotted as a function of the regularization parameter. Grade this solution according to the following rubric (each category is equally weighted): \n",
    "\n",
    "- correctness\n",
    "\n",
    "- interpretation (if applicable)\n",
    "\n",
    "- code/algorithm design\n",
    "\n",
    "- presentation\n",
    "\n",
    "In addition to providing an holistic grade (between 0 to 5), provide a corrected version of this code that is submission quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12db996d0>]"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4lVW2x/HvCqFHxQYiKKgISVAQGJooBnVEdEQUC+Id\n7KIoMjakaQBFUcauODqWsTuKDey02LHRAkHANiB2BRURKdn3j3WQiIGQnJqc3+d5zsMp73nfbe7c\n9e6z9t5rWwgBERGp+jKS3QAREUkMBXwRkTShgC8ikiYU8EVE0oQCvohImlDAFxFJE5nxvoCZfQb8\nCBQDa0MIHeJ9TRER+bO4B3w80OeFEJYn4FoiIrIZiUjpWIKuIyIiW5CIQByAyWb2npmdlYDriYhI\nKRKR0ukSQvjSzHbGA/+CEMIbCbiuiIiUEPeAH0L4MvLvt2b2NNAB+D3gm5mK+YiIVEAIwcpzfFxT\nOmZWx8yyIs/rAocB8zY9LoSgRwjk5+cnvQ2p8tDfQn8L/S22/KiIePfwGwBPR3rxmcDDIYRX4nxN\nEREpRVwDfgjhU2C/eF5DRES2jqZLppC8vLxkNyFl6G+xkf4WG+lvER2raC4oZg0wC8lug4hIZWNm\nhFQatBURkdShgC8ikiYU8EVE0oQCvohImlDAFxFJEwr4IiJpQgFfRCRNKOCLiKQJBXwRkTShgC8i\nkiYU8EVE0oQCvohImkjEFodl+vlnKC7253XqQPXqyW2PiEhVlBLVMiFQvTrUqgWrVkFmJmyzDWRl\n+b8VeZT8brVqSf1PFBGJuYpUy4x7wDezw4Gb8PTRPSGEazf5PBxzTOCDD2DMGOjbF377zXv95Xms\nXLn592vV2vLNYdttoU8faN8+rn8KEZGYSbmAb2YZwCLgEOAL4D2gTwjhwxLHhBACb7wBl1wCa9fC\nuHFw8MGxaUNxsf9q2NLN4ptvYPx46NXLbzo77BCba4uIxEsqBvxOQH4IoUfk9RAglOzll9wAJQSY\nMAGGDIHsbLjuOmjZMm7N+4Ply2HECHjySRg7Fvr1gwwNaYtIikrFgN8b6B5CODvy+v+ADiGEC0oc\nE5b9tOwP3/vtN3jgAbjlFujeHS69FBo0iE8b16xfw4rVK1hXvA6AoiIP+DVq+I2nWbP4XFdEJBrt\nG7WvnAGfg/x5Vo0sauxVg5rNagLe4//5Z0/J1K3rA7G2yX/emvVr+PG3H38P2CIiVdKnwGclXr9K\nuQN+vKdlLgN2L/G6ceS9Pxh+xXDu/OBOLu96OTk75bBi9Yo/PJZ8u4LX31vBV0tW0LjZCmput4IV\nv/lna9avoV6ten9+1CzlvVIedarXwTa9i0R88w0MHgxTpsANN8Dxx//5hiMikgybi1tb/E6ce/jV\ngIX4oO2XwLvASSGEBSWOCSEE5n8zn2HThvHLml9KDczb19qeb5fW44G76vHjN/W44tJ69D6yHnVr\nbD5gx8rrr8OAAbDLLnD77dC8eVwvJyJSppTL4cPv0zJvZuO0zLGbfB7K04YQ4PnnvefdoAH885/Q\nrl1s21yatWvh1lvh6qvh3HNh6FBfJCYikgwpGfDLbEA5A/4G69bBPffAqFE+hXPMGGjSJA4N3MSy\nZXDRRfDuu34D+Nvf4n9NEZFNVSTgV9qJh5mZ0L8/LFwIe+0Fbdt6r3/Fivhet1Ej+O9/4c47PfAf\nfTR89ll8rykiEguVNuBvsM023ssvLPS59M2bw003wZo18b3uYYf5Ndu395TS1Vf7dFIRkVRV6QP+\nBrvuCv/+N0ybBpMnQ04OPPGE5/zjpWZNX6z1/vvw1lvQujVMnRq/64mIRKPS5vDLMnWql2qoVcsH\ndrt0ifkl/iAEmDgRBg2Czp3h+uv9JiQiEg9plcMvyyGHwAcf+HTKk06CY4+FRYvidz0zz+fPnw97\n7AGtWnlqaZ3Wg4lIiqiyAR+8Fs7f/+4Dux06wP77w8CB8O238btm3bqez3/jDZg0yfP7b70Vv+uJ\niGytKh3wN6hd2+viLFjgPfGcHLjmGvj11/hdMzvbV+gOHeordM84A777Ln7XExEpS1oE/A123tkL\nsr39tqd7WrSA++/fuNtWrJl5nf2iIp9NlJsLd90Vv+uJiGxJlR203RpvveUDu7/+6jX4Dz00vteb\nPdvHFIqLvf5+27bxvZ6IVF1ptdI2VkLwGvhDhsDee3sN/n33jd/1iovhvvtg2DA44QS48kqoVy9+\n1xORqkmzdCrADI47ztMuPXp4L//MM+GLL+JzvYwMz+cXFflCrZwceOih+K4XEBEBBfzf1agBF1zg\nM3p23NF7+Vdc4fX442HHHT2f//TTXnq5Wze/CYiIxIsC/ibq1YNrr4WZM+HTT71Uw7/+Fb/59J06\neSG23r3hoIPgsst843URkVhTwN+MJk3gwQe9FPMTT3iPf+LE+KReMjN9fUBhoVfjzM2Fp55SmkdE\nYivtB223Rgjw4ou+t+7OO3uphr/8JX7Xmz4dzjsPmjb1Esx77RW/a4lI5aRB2zgxgyOOgDlz4OST\noWdP6Ns3fmWRu3XzKZx5eb5CeNQoWL06PtcSkfQRt4BvZvlm9rmZzYw8Do/XtRIlMxPOOstr8rRo\n4WUTLrnEyzLHWo0aXt9/1iy/0eyzD7z0UuyvIyLpI949/BtCCG0jjyoTrrKyID8f5s3zWTwtWsCN\nN8anHv7uu3s+/5ZbPM1z3HGwdGnsryMiVV+8A358dxdPsoYNfeer6dO9HHNOju+GFY8hiSOO8BtM\ny5bQpo2vDF67NvbXEZGqK26DtmaWD5wK/Ai8D1wcQvixlONSftB2a02f7imezEwf2D3wwPhcZ/Fi\nn9WzdKmXaDjooPhcR0RSV8JLK5jZZKBBybeAAAwHZgDfhRCCmV0FNAwhnFHKOUJ+fv7vr/Py8sjL\ny6twm5KtuBgefdRLJ7RtC2PHeson1kLwVM8//uGDvOPGQYMGZX9PRCqngoICCgoKfn89atSo1Kyl\nY2ZNgEkhhFalfFZlevglrV7tefdx47xmTn4+1K8f++usXAmjR3t9npEj4ZxzoFq12F9HRFJLSk3L\nNLNdSrw8FpgXr2ulolq1fJbNhx9C9eq+mGrMGFi1KrbXycrygm/Tp/v4QYcO8M47sb2GiFQN8Ry0\nvc7M5prZbOAg4MI4Xitl7bijb3X4zjs+vbJFC/jPf2D9+theZ5994NVXPcXTqxf07w8//BDba4hI\n5aaVtgn29ts+sLtypad7Djss9tdYsQJGjIAJE3xnr1NO8SqdIlJ1qB5+JRGCV8m87DLYc08P/K3+\nNLoRvQ8+gHPP9ZTSHXfE5xoikhwplcOXzTODY4/1cshHHeW9/NNP98JpsdSunf+i6NfP6/xfdBH8\n9FNsryEilYcCfhJVrw7nn+81+Bs08B74iBGxDcrVqnk+f/58T/Xk5sJjj6kSp0g6UkonhSxd6gH/\n5Zd985WzzvKbQiy9+aaneerXh9tvj88aARGJP6V0KrnddoP77/dSzE895TX4n302tr3xLl18c5cj\nj/Tnw4fHfqqoiKQm9fBTVAheHXPwYNh+ey/V0KFDbK+xbBlcfLFPGb3lFh9PEJHKQbN0qqD1633e\n/hVXeG2eq6/2mT2xNGWKV+Js0cIDf9OmsT2/iMSeUjpVULVqcMYZXoO/ZUto395n28RyUdWhh8Lc\nudCxo+/kNWZMfEo9i0hyKeBXEnXrwuWX+2ybVau8N3799bELzDVrej7/vfc8xdOqlff8RaTqUEqn\nklqwwBduFRZ6mufEE2O7mnbiRLjgAujUCW64AXbdNXbnFpHoKaWTRnJyPCjfd5/39Dt18lo6sdKz\npy8M22sv7+3feCOsWxe784tI4qmHXwUUF/tiqmHDoHVruPZayM6O3fk//NAXiH37rW+40qVL7M4t\nIhWjHn6aysiAvn09MB94oD/OPRe+/jo258/OhsmT/YZywgleBuLbb2NzbhFJHAX8KqRWLa/E+eGH\nULu2z+q56qrYLKwy83GCBQtgu+383Hfe6b8uRKRyUEqnCvv4Y++Vv/mm74p1yimx2w1rzhwYMMDz\n+uPHe6E2EUkcLbySUr3zjvf8f/zRd8fq3t177NEqLvZFYUOHwvHH+6+JevWiP6+IlC3hOXwzO87M\n5pnZejNru8lnQ81ssZktMLM4bPMhW6tjR3jtNe/lDxrk5Zhnz47+vBkZns8vKoK1a33m0IMPqhKn\nSKqKNodfCBwD/GFCoJnlACcAOUAPYLxZLPqUUlFmvvXhvHlwzDFw+OFw6qnw+efRn3vHHT2f/8wz\nPn0zL88XiIlIaokq4IcQFoYQFgObBvOjgcdCCOtCCJ8Bi4EYl/6Siqhe3XPvixZBo0Y+jXPYsNjU\n4O/Y0VfqnnCCB/3Bg30rRxFJDfGapdMIWFri9bLIe5Iitt3Wa+bMmQNffgnNm3t9/LVroztvtWpe\niK2w0M+bmwtPPqk0j0gqyCzrADObDDQo+RYQgOEhhEmxaMTIkSN/f56Xl0deXl4sTitboXFjX607\nZw5ceqlXyxw71tM/0SThdtnF8/kFBX4DuPtuuPVWaNYsZk0XSSsFBQUUFBREdY6YzNIxs+nAxSGE\nmZHXQ4AQQrg28volID+E8E4p39UsnRTy8sse+Lfd1mvwd+oU/TnXroWbbvIVwOef7zWAateO/rwi\n6SzZK21LXngi0MfMapjZHkAz4N0YXkvipHt3mDXLSzIfd5zn4z/+OLpzVq/uN5FZs3zQeJ99fFcv\nEUmsaKdl9jKzpUAn4DkzexEghFAEPA4UAS8AA9SNrzyqVYPTTvOB3datfTD2wgvh+++jO+9uu8GE\nCXDbbTBwIPTu7fv4ikhiRDtL55kQwm4hhNohhIYhhB4lPrsmhNAshJATQngl+qZKotWp4zXy58/3\nuvvZ2TBuHKxeHd15e/Twnn6rVtCmjS8GW7MmNm0Wkc1TLR0pU4MGXj7h9de9TEN2Njz8cHR1dGrV\ngvx8XwU8fTrst58P8IpI/Ki0gpTba695qYbiYu/xd+sW3flCgKefhn/8A7p29cHiXXaJTVtFqqpk\nD9pKmujaFWbM8KB/xhlw1FFeXqGizODYY/0cjRrBvvt6nn/9+ti1WUQU8KWCMjKgTx8vl9ytm6+s\n7d8fvvqq4ufMyvKpmwUFPrjbvr2nfEQkNhTwJSo1a8JFF3kN/qwsr5M/ejT88kvFz9mypef1L7rI\n6/6cfXb0M4RERAFfYmSHHXxv3fff915/8+a+uraiaRkz+L//8zRPzZpeouGee7Thikg0NGgrcfHu\nu77Y6vvvfdpljx7RlWqYOdO3baxWDe64w9cHiKQzbYAiKSUEmDTJq2Y2buwzetq0qfj5iov9V8OI\nEb6H7+jRXgJCJB1plo6kFDPo2dMrZ/buDUccAf36wZIlFTtfRobn8+fPh59/9g1XHntMlThFtpYC\nvsRd9eqejlm0CJo08V7+kCG+5WJF7Lyz5/OfeAKuuQYOPdQHjUVkyxTwJWG22QauvBLmzoVvvvGB\n3VtuqXhZhf33hw8+8HUABxzgG7msWhXbNotUJQr4knCNGsG998LkyfDCCz4Ns6KbpGRm+grduXPh\n0099Ns/EibFvs0hVoEFbSbrJk31GT926Xlahc+eKn2vqVN9wZe+9/dfDHnvErp0iqUSDtlIp/fWv\nnpo5+2yvv3/88fDRRxU71yGH+O5dnTv7St2rrvJKnyKigC8polo1OOUUWLjQB3U7dYJBg+C778p/\nrpo1PZ///vu+qfq++/qvCJF0F+0GKMeZ2TwzW29mbUu838TMVpnZzMhjfPRNlXRQp44H66IiX6Wb\nne31dX79tfznatoUnn3WVwCffTaceCIsWxbzJotUGtH28AuBY4BXS/nsoxBC28hjQJTXkTRTv75X\nzHzzTS+glp0NDz1UsdIKRx3lc/f33ttX6N5wg++zK5Juot3xamEIYTF/3M92gygW0ou4Fi3gqad8\nw5XbbvO8/LRp5T9PnTqez3/zTd9Pt107eOON2LdXJJXFM4ffNJLOmW5mB8TxOpIGDjgA3n4bLrsM\nzjoLjjzSe+3l1aIFvPKKl2fo08f37v3mm9i3VyQVlRnwzWyymc0t8SiM/HvUFr72BbB7CKEtcDHw\niJllxarRkp7MfBZPUZHP7OnWzYP/l19W7DwLFniVz332gX/9SxuuSNUXk3n4ZjYduDiEMLO8n5tZ\nyM/P//11Xl4eeXl5UbdJqr7ly+Hqq30R18CBvgNXVgW6FXPnwoABvuL3jjs83SOSagoKCigosfHz\nqFGjklMtMxLQLwkhfBB5vRPwQwih2Mz2xAd19w0hrCjlu1p4JVH57DMYPtw3TRk5Ek4/3Vfglkdx\nMTzwgNf46d3b8/3bbx+P1orERsIXXplZLzNbCnQCnjOzFyMfdQXmmtlM4HGgf2nBXiQWmjb1Qd2J\nE+HRR30mzvPPl69UQ0YGnHqqp4uKi71EwwMPqBKnVC0qrSBVSgjw3HNeg79hQy/V0LZt2d/b1Hvv\neYXPOnVg/HjP84ukEpVWkLRn5vPuCwt9odWRR/pWif/7X/nOs2ED9T59fHD40kth5cr4tFkkURTw\npUrKzIT+/b0G/557ei9/8GBYUY7EYrVqPpg7b55P3czJgQkTlOaRyksBX6q0bbbxrRALC+GHH3we\n/s03l68Gf4MGcP/9Pk4wcqTvz7t4cdyaLBI3CviSFnbd1ffDnToVXn7ZB2WfeKJ8vfWuXWHWLN9h\nq3NnyM+vWI0fkWTRoK2kpalTfd5+7do+sLv//uX7/uefw4UXwsyZcOutvl+vSCJVZNBWAV/SVnGx\nF2QbMcIHaceO9QJr5fHyy3D++T6L5+abYffd49NWkU1plo5IOWRkQL9+XoO/fXtP0wwcCN9+u/Xn\n6N7dxwfatPGB4WuvrfgevSLxpoAvaa92bV9hu2CBT+vMyYFrrtn6/HytWnDFFT6N87XXYL/9fNWv\nSKpRwBeJ2Hln3wf37bd9t6wWLXy17dbW4N9rL1/0NWaMr9o9+eTyF3YTiScFfJFN7L03PPmkl2nY\nUExtypSt+64ZHHOMl2jYbTdo1cpvIuvWxbfNIltDg7YiWxCCB/8hQ/xGcN11vkfu1ioqgvPO8wVf\nd9zhe/WKxIIGbUVizAyOO84D9+GHwyGHwJlnwhdfbN33c3N9h65LLoFjj/X6/d9/H982i2yOAr7I\nVqhRAwYN8lINO+7ovfwrroCffy77u2aez1+wwAeIc3N9EVhF9ucViYYCvkg51KvnUy9nzoRPP4Xm\nzeHOO7cuR7/ddp7Pf+klD/hdusDs2fFvs8gGCvgiFdCkCTz4oM/K+e9/fXB20qStK9XQpg289ZZv\n1NK9u/9y+PHH+LdZRAFfJArt2nmZhnHjfGC3Wzef0lmWjAzP58+fD7/84mmeRx9VJU6Jr2h3vLrO\nzBaY2Wwze9LMti3x2VAzWxz5/LDomyqSmsy87v6cOZ6r79kT+vb1rRfLstNOnt6ZMMFTRYcc4rl+\nkXiItof/CtAyhLAfsBgYCmBmucAJQA7QAxhvZuWaPiRS2WRmeq990SLP7bdr5xunLF9e9nc7d/Zf\nBr16wYEHwtCh3vMXiaWoAn4IYUoIYcNcgxlA48jznsBjIYR1IYTP8JtBh2iuJVJZZGV53fx58zw3\n36IF3Hgj/Pbblr+XmQkXXOC1ef73P2jZEp55RmkeiZ1Y5vBPB16IPG8ELC3x2bLIeyJpo2FDuOsu\nr6szdarn6f/737IDeMOG8MgjcO+93tM/6ij45JPEtFmqtjIDvplNNrO5JR6FkX+PKnHMcGBtCOHR\nuLZWpBJq2dJn8/z7356n79QJXn+97O8dfLCPCxxwAHToAFdeWfavBJEtySzrgBDCX7f0uZmdChwB\nHFzi7WXAbiVeN468V6qRI0f+/jwvL4+8vLyymiVS6Rx8sOfpH3nEN1Zv29Zr8Ldosfnv1Kjhs39O\nOgn+8Q9f8HXbbXCYpkGknYKCAgoKCqI6R1S1dMzscOB6oGsI4fsS7+cCDwMd8VTOZGDv0ormqJaO\npKPVq30R1rhxcMIJvl1i/fplf++55zzP/5e/wA03QOPGZX9HqqZk1NK5FcgCJpvZTDMbDxBCKAIe\nB4rwvP4ARXWRjWrVgsGDfQpm9eqe37/6ali1asvf+9vffO5+drbX3b/+eli7NjFtlspP1TJFUsBH\nH/kA7YwZnqv/+9+hWrUtf2fRIt+h64svYPx4n84p6UN72opUcm+/7ZU1V670dE9ZufoQfNHWRRf5\noq3rrtu61JBUfiqPLFLJde4Mb7zhlTjPO89r7cydu/njzeD447188047+YygO+6A9esT12apPNTD\nF0lRa9Z4Jc6rrvLSDVdeCY3KWM1SWAgDBvig8Pjxvjm7VE3q4YtUITVqeI5+0SJo0MArco4YseUa\n/Pvu6xupn3++1/QZMGDrSjtIelDAF0lx220H11wDs2bBkiW+1eL48ZufnWMGp5ziaR6AnBy4/36V\naBCldEQqnVmzvCjb55/7yt2ePT3Ib85773lPv1Ytv1GUZ09eSV2apSOSJkLwnbMuvRR22AH++U8v\nv7A569d7XZ8rroB+/by42zbbJKy5EgfK4YukCTPo0cO3SOzXD445xssvfPpp6cdXqwbnnuuLtr7/\n3tM8TzyhNE+6UcAXqcQyM+HMM31gNyfHSy5cfDH88EPpx9evD//5j++uNXq0T/tctCihTZYkUsAX\nqQLq1vV0zYYtE7OzvezC5qprHnigb8TevTvsvz9cfjn8+mti2yyJp4AvUoXssgv8619QUOCP7Gzv\nzRcX//nY6tX918Ds2bBw4cYyzlJ1adBWpAorKPBSDRkZPrDbtevmj33lFV/d27Il3HwzNGmSsGZK\nBWjQVkT+IC8P3n3Xa+n36wdHHw0fflj6sYcd5it127Xzx9ixvtpXqg4FfJEqLiMD+vb1QH/ggf4Y\nMAC+/vrPx9aq5fn8d9/1mj6tW8O0aYlvs8SHAr5ImqhVy9M7H34INWt66uaqq0qvwb/nnjBpkvfy\nTzvNbxhffpn4NktsKeCLpJkdd4Qbb4R33vEUTvPmvmH6phU2zTwFVFTk+fx99/Xc/rp1yWm3RC/a\nLQ6vA44CfgM+Bk4LIfxkZk2ABcCGbOGMEMKAzZxDg7YiSTRjhvf8f/rJa/B37176cQsW+KDuDz94\nCebOnRPbTvmjhJdWMLNDgWkhhGIzGwuEEMLQSMCfFEJotRXnUMAXSbIQ4Jln4LLLoGlTD/ytW5d+\n3GOP+Q2iRw9P+ey0U8KbKyRhlk4IYUoIYcMM3xlAyS2Vy9UQEUkeMy/PMH++p3G6d4dTT/UCbZse\nd9JJnubJyvJxgLvvLn2ev6SeWObwTwdeLPG6aWRj8+lmdkAMryMicVK9uqdtFi3yzVZat4Zhwzzd\nU9J228FNN8HLL8M990CXLl7FU1JbmSkdM5sMNCj5FhCA4SGESZFjhgNtQwi9I6+rA1khhOVm1hZ4\nBsgNIaws5fwhPz//99d5eXnk5eVF9R8lIrGxdKlP03zpJf/37LP9plBScTHcd5/fGE480Xfm2m67\n5LS3KisoKKCgoOD316NGjUp8eWQzOxU4Czg4hFBq5Q4zmw5cHEKYWcpnyuGLpLjZs70U85Ilnrfv\n1evPNfi/+w6GDoXnn/cxgL59t1ynX6KTjEHbw4Hrga4hhO9LvL8T8ENkMHdP4FVg3xDCilLOoYAv\nUgmE4CmcwYO9B//Pf0LHjn8+bsYML8Vcr55vuJKTk/i2poNklFa4FcgCJkfy9eMj73cF5prZTOBx\noH9pwV5EKg8zOPxwz9Wfdhr07u0pnI8//uNxnTr5LlvHHuu1e4YM8QqeknwqniYiFfLLL76A68Yb\nvU7PiBG+qKukL7/0VNDrr/sgb2mpIKkYFU8TkYSpW9eDfFERrF7tpZjHjfPnGzRsCA895JuuDB8O\nf/sbfPJJ0pqc9hTwRSQqDRr4ytvXX/eCa9nZ8Mgjf5yb362bD/x27ep7744e/ccbgySGUjoiElOv\nvuppnOJiH9jddJb1kiVerrmwEG67bfOlHGTLEj5LJxYU8EWqnuJiePxxn6a5zz5w7bWQm/vHY55/\nHgYO9Nr7N94IjRuXfi4pnXL4IpISMjKgTx8vxZyXBwcdBP37w1dfbTzmyCO9lENuLuy3n/8aWLs2\naU1OCwr4IhI3NWv6vrkLF26svTN69MZpmrVrw6hR8PbbMGUKtGkDr72W3DZXZQr4IhJ3O+wA11/v\n8/OLirwG/913b6zBv/fe8OKLMHIknHwynHJK6TtySXQU8EUkYfbc08srP/00PPCAp3JefNFX8ZrB\nccf5DaF+fc/9jx//541ZpOI0aCsiSRECTJzoNfgbN/Y5/G3abPx83jzfe3fVKg/8HTokr62pSIO2\nIlJpbNhCsbDQyzT06OErdpcs8c/32ceneF5wgR937rm+25ZUnAK+iCRV9eoezBctgt13917+0KHw\n449+U+jXz9M8GRk+o+c//9GGKxWlgC8iKWHbbeGqq2DOHB+wbd4cbr0V1qyB7beH22+H557z9M5B\nB/kvAykfBXwRSSmNG8O998Lkyb44q2VLePJJz/n/5S8+hfPkk+GQQ+Cii+Dnn5Pd4spDAV9EUlKr\nVr7T1u23+9z9Aw7wYF+tGpxzjg/qLl/u9fYff9xvCLJlmqUjIilv/Xp48EHfZrFTJ7jmGmjWzD97\n4w2fzdOggd8cmjdPblsTRbN0RKRKqlYNTj3VV+y2aeNBf9Ag31bxgAPggw/giCNg//39prBqVbJb\nnJqiCvhmNtrM5pjZLDN7ycx2KfHZUDNbbGYLzOyw6JsqIumuTh3fLL2oCNat81LM113nvwAuvNAH\nfBct8rz/pEnJbm3qiXZP26wQwsrI84FAbgjhXDPLBR4G2gONgSnA3qXlbpTSEZGKWrjQt1CcORPG\njPGN0zMyfMD3vPM8v3/zzdC0abJbGnsJT+lsCPYRdYENs2N7Ao+FENaFED4DFgNaJyciMdWihZdp\neOghn8LZvj1MmwZ//atP22zf3mf2XH01/PZbslubfFHn8M3sKjNbAvQFroi83QhYWuKwZZH3RERi\n7sADYca8BSbKAAAJkklEQVQMGDwYzjzTSy9/9JFvwfjeez67p3VrmDo12S1NrsyyDjCzyUCDkm8B\nARgeQpgUQhgBjDCzy4CBwMjyNmLkyI1fycvLI2/TLXJERMpgBiee6Buljx/v2yr26uXllydN8ro9\nZ5wBnTt75c5dd012i8unoKCAgoKCqM4Rs2mZZrYb8HwIoZWZDQFCCOHayGcvAfkhhHdK+Z5y+CIS\nc8uXeyrn3nt9Z61LLvH8/pgxcOed3vs//3zILLPbm5oSnsM3s2YlXvYCPow8nwj0MbMaZrYH0Ax4\nN5priYiUx/bbewXO99/3mTvNm3uuf9Qon7s/aZJvr/jWW8luaeJEm8Mfa2ZzzWw2cCgwCCCEUAQ8\nDhQBLwAD1I0XkWTYYw945BF49ln/t3Vr+Phj32Fr6FA4/nhP9Xz3XbJbGn9aaSsiaSMEL8A2eDA0\nbOj76DZrBvn58PDDXrztzDM99ZPqKpLSUcAXkbSzbp1vsThqlBdhGzPGc/4DBnjp5fHjoW3bZLdy\ny1RaQURkK2RmegG2RYt828W2beHRR70659lne5mGgQNhxYpktzS2FPBFJG1ts41X4pw713P42dle\nbnn2bK/Dn5vrA71VJQmhlI6ISERhoef3Fy/2ipy77eZpnm239TRPbm6yW7iRcvgiIjEwZQpceinU\nrg3XXutF2UaNgtNP92qcWVnJbqFy+CIiMXHooV5y+ZxzfHet6dPhqafgiy+8EudTT1XONI8CvohI\nKTIyfAP1hQu9ANsxx0C9el6W4fLLvV7Pxx8nu5Xlo4AvIrIFtWv7Aq0FC/z1OedAnz7QsaM/Ro2C\n1auT28atpRy+iEg5LFrkN4D33oP+/b10Q2Eh3HYbHH544tqhQVsRkQR5800vyLZ6tS/eevpp2G8/\nuOkmn90Tbxq0FRFJkC5dvPDasGEe7Hff3Us0t2njRdvWrk12C/9MPXwRkSitWQN33OElGlq2hB9+\n8PIN48fDQQfF55rq4YuIJEGNGjBokOf327eHzz/33v4xx/hMn6+/TnYLnQK+iEiM1KsH113nm6rv\nt5/38p991jdTv/12WL8+ue1TSkdEJE4++MBX7E6f7q/btvU0T8eO0Z9bKR0RkRTSrp1vnP7cc97L\nnznT99Tt39/z/IkW7RaHo81sjpnNMrOXzGyXyPtNzGyVmc2MPMbHprkiIpWLma/KnTvX99KtXx/u\nugtatID77vP6+wlrSzTpFDPLCiGsjDwfCOSGEM41sybApBBCq604h1I6IpI2Vq70nbbGjYNVq2D/\n/X2GT6syo+UfJTylsyHYR9QFSt6rytUQEZF0kJUFI0d6CeYzz4QZMzy3f+GF8NNP8b121Dl8M7vK\nzJYAfYErSnzUNJLOmW5mB0R7HRGRqmTXXeHf//ZUT/fuvkI3Oxseeyx+lTjLTOmY2WSgQcm3gAAM\nDyFMKnHcZUDtEMJIM6sB1A0hLDeztsAzeLqn5C+CDd8L+fn5v7/Oy8sjLy8viv8kEZHKZ9o0L9Uw\na5aXarj9ds/zb1BQUEBBQcHvr0eNGpW8WjpmthvwQghh31I+mw5cHEKYWcpnyuGLiOADuA8/DMOH\nw1df+ZTO4cOhTp0/H5vwHL6ZNSvxshewIPL+TmaWEXm+J9AM+CSaa4mIVHUZGfD3v3sN/iuv9Aqc\nubkwaVLZ392q80f5/bFmNtfMZgOHAoMi73cF5prZTOBxoH8IoYrt/y4iEh+1a8Nll/kGK0cfDcce\nCz17wqefRnderbQVEUlxH33kNfiff95TPJdcArVqqR6+iEiV9dZbHuy//x4WLVLAFxGp0kLw+vu9\neyvgi4ikBRVPExGRzVLAFxFJEwr4IiJpQgFfRCRNKOCLiKQJBXwRkTShgC8ikiYU8EVE0oQCvohI\nmlDAFxFJEwr4IiJpQgFfRCRNxCTgm9nFZlZsZjuUeG+omS02swVmdlgsriMiIhUXdcA3s8bAX4H/\nlXgvBzgByAF6AOPNrFxV3dJRyQ2K053+Fhvpb7GR/hbRiUUP/0bg0k3eOxp4LISwLoTwGbAY6BCD\na1Vp+h/zRvpbbKS/xUb6W0Qn2k3MewJLQwiFm3zUCFha4vWyyHsiIpIkmWUdYGaTgQYl3wICMAIY\nhqdzREQkxVV4xysz2weYAqzCbwKN8Z58B+B0gBDC2MixLwH5IYR3SjmPtrsSEamApG1xaGafAm1D\nCMvNLBd4GOiIp3ImA3trL0MRkeQpM6VTDgHv6RNCKDKzx4EiYC0wQMFeRCS5kr6JuYiIJEZSV9qa\n2eFm9qGZLTKzy5LZlmQys8ZmNs3M5ptZoZldkOw2JZOZZZjZTDObmOy2JJuZbWdmT0QWMM43s47J\nblOymNmFZjbPzOaa2cNmViPZbUoUM7vHzL42s7kl3tvezF4xs4Vm9rKZbVfWeZIW8M0sA7gN6A60\nBE4ys+xktSfJ1gEXhRBaAp2B89L4bwEwCE8HCtwMvBBCyAFaAwuS3J6kMLNdgYH4OGErPB3dJ7mt\nSqj78FhZ0hBgSgihBTANGFrWSZLZw+8ALA4h/C+EsBZ4DF+wlXZCCF+FEGZHnq/E/586LdctRFZu\nHwHcney2JJuZbQscGEK4DyCykPGnJDcrmaoBdc0sE6gDfJHk9iRMCOENYPkmbx8N3B95fj/Qq6zz\nJDPgb7o463PSNMiVZGZNgf2AP01hTRMbVm5rcAn2AL4zs/siKa67zKx2shuVDCGEL4DrgSX49O8V\nIYQpyW1V0tUPIXwN3mkE6pf1BVXLTCFmlgVMAAZFevppxcyOBL6O/NqxyCOdZQJtgdtDCG3xNS9D\nktuk5DCzeniPtgmwK5BlZn2T26qUU2YnKZkBfxmwe4nXGxZupaXIz9QJwIMhhGeT3Z4k6QL0NLNP\ngEeBbmb2QJLblEyf46VL3o+8noDfANLRocAnIYQfQgjrgaeA/ZPcpmT72swaAJjZLsA3ZX0hmQH/\nPaCZmTWJjLb3AdJ5Vsa9QFEI4eZkNyRZQgjDQgi7hxD2xP/3MC2E0C/Z7UqWyM/1pWbWPPLWIaTv\nYPYSoJOZ1YpU3j2E9BvA3vRX70Tg1MjzU4AyO4qxXHhVLiGE9WZ2PvAKfuO5J4SQbv8HBMDMugAn\nA4VmNgv/aTYshPBSclsmKeAC4GEzqw58ApyW5PYkRQjhXTObAMzCF3POAu5KbqsSx8weAfKAHc1s\nCZAPjAWeMLPT8fL0J5R5Hi28EhFJDxq0FRFJEwr4IiJpQgFfRCRNKOCLiKQJBXwRkTShgC8ikiYU\n8EVE0oQCvohImvh/H95nrAmomMwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125063410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit\n",
    "def ridge(x_train, y_train, reg_param):\n",
    "    n=np.shape(x_train)[0]\n",
    "    x_train=np.concatenate((x_train,reg_param*np.identity(n)),axis=1)\n",
    "    y_train_=np.zeros((n+np.shape(x_train)[1],1))\n",
    "    for c in range(n):\n",
    "        y_train_[c]= y_train[c]\n",
    "    import sklearn\n",
    "    model = sklearn.linear_model.LinearRegression()\n",
    "    model.fit(x_train,y_train)\n",
    "    return model\n",
    "\n",
    "# Score\n",
    "def score(m,x_test,y_test, reg_param):\n",
    "    n=np.shape(x_train)[0]\n",
    "    x_test=np.concatenate((x_test,reg_param*np.identity(n)),axis=1)\n",
    "    y_test_=np.zeros((n+np.shape(x_train)[1],1))\n",
    "    for c in range(n):\n",
    "        y_test_[c]= y_test[c]\n",
    "    return m.score(x_test,y_test)\n",
    "\n",
    "# Load\n",
    "data = np.loadtxt('datasets/dataset_3.txt', delimiter=',')\n",
    "n = data.shape[0]\n",
    "n = int(np.round(n*0.5))\n",
    "x_train = data[0:n,0:100]\n",
    "y_train = data[0:n,100]\n",
    "x_test = data[n:2*n,0:100]\n",
    "y_test = data[n:2*n,100]\n",
    "\n",
    "# Params\n",
    "a=np.zeros(5)\n",
    "for i in range(-2,2):\n",
    "    a[i+2]=10**i\n",
    "\n",
    "# Iterate\n",
    "rstr =np.zeros(5)\n",
    "rsts =np.zeros(5)\n",
    "for j in range(0,5):    \n",
    "    m =ridge(x_train,y_train,a[i])\n",
    "    rstr[j]=score(m,x_train,y_train,a[j])\n",
    "    rsts[i]=score(m,x_test,y_test,a[i])\n",
    "\n",
    "# Plot\n",
    "plt.plot(a,rstr)\n",
    "plt.plot(a,rsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would give this student a grade of 3/5. In terms of correctness, the x_train matrix is concatenated along the wrong axis and by using the wrong identity matrix. The indexes of the r squared calculations are off and the plot is illegible since the datapoints are not properly ordered. The plot does not have axes and is unsorted, which makes interpretation difficult since we can't discern data trends. In terms of code design, the student does a good job writing separate functions which can be repeatedly called. This is a very efficient use of function reusability. In terms of presentation, the code could benefit from additional comments, which could give the reader a clearly picture of the mathematical steps. Additional comments within each function can help better outline every step of the process and how it relates to 3a. I would also load the data up top to make the data sequence more coherent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAGDCAYAAADeRuzbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYuEUkqpNGmRUEoplSYtEkoppdL0/7cO9mAnY4grAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bafe850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data and split into training and testing sets for x and y\n",
    "data = np.loadtxt('datasets/dataset_3.txt', delimiter=',')\n",
    "n = data.shape[0]\n",
    "n = int(np.round(n*0.5))\n",
    "x_train = data[0:n,0:100]\n",
    "y_train = data[0:n,100]\n",
    "x_test = data[n:2*n,0:100]\n",
    "y_test = data[n:2*n,100]\n",
    "\n",
    "# Fit our data to OLS model\n",
    "def ridge(x_train, y_train, reg_param):\n",
    "    n=np.shape(x_train)[0]\n",
    "    p=np.shape(x_train)[1]\n",
    "    \n",
    "    # concatenate identity matrix of square root of lambdas \n",
    "    x_train=np.concatenate((x_train,(np.sqrt(reg_param)) * np.identity(p)), axis=0)\n",
    "    \n",
    "    # extend y_train with zeroes to length of x_train\n",
    "    y_train_zeros=np.zeros((n+p,1))\n",
    "    for c in range(n):\n",
    "        y_train_zeros[c]= y_train[c]\n",
    "    import sklearn\n",
    "    \n",
    "    # fit data to a linear regression model\n",
    "    model = Lin_Reg()\n",
    "    model.fit(x_train, y_train_zeros)\n",
    "    coefficients = model.coef_\n",
    "    return model\n",
    "\n",
    "# obtain r squared values for data given model\n",
    "def score(m,x_test,y_test, reg_param):\n",
    "    n=np.shape(x_test)[0]\n",
    "    p=np.shape(x_test)[1]\n",
    "    \n",
    "    # concatenate identity matrix of square root of lambdas \n",
    "    x_test=np.concatenate((x_test,(np.sqrt(reg_param)) * np.identity(p)), axis=0)\n",
    "    \n",
    "    # extend y_test with zeroes to length of x_test\n",
    "    y_test_zeros=np.zeros((n+p,1))\n",
    "    \n",
    "    for c in range(n):\n",
    "        y_test_zeros[c]= y_test[c]\n",
    "    return m.score(x_test,y_test_zeros)\n",
    "\n",
    "# Create matrix of varying lambda values\n",
    "a=np.zeros(5)\n",
    "for i in range(-2,3):\n",
    "    a[i+2]=10**i\n",
    "\n",
    "# Iterate through all lambda values and store r squared output\n",
    "rstr =np.zeros(5)\n",
    "rsts =np.zeros(5)\n",
    "for j in range(0,5):    \n",
    "    m = ridge(x_train,y_train,a[j])\n",
    "    rstr[j]=score(m,x_train,y_train,a[j])\n",
    "    rsts[j]=score(m,x_test,y_test,a[j])\n",
    "\n",
    "# Plot r squared output on a semilog plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "ax.semilogx(10.0**np.arange(-2, 3),rstr, label =\"training\")\n",
    "ax.semilogx(10.0**np.arange(-2, 3),rsts, label = \"testing\")\n",
    "plt.xlabel('Lambda'); \n",
    "plt.ylabel('R Squared Values')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: Predicting Outcome of a Fund-raising Campaign\n",
    "You are provided a data set containing details of mail sent to 95,412 potential donors for a fund-raising campaign of a not-for-profit organization. This data set also contains the amount donated by each donor. The task is to build a model that can estimate the amount that a donor would donate using his/her attributes. The data is contained in the file `dataset_4.txt`. Each row contains 376 attributes for a donor, followed by the donation amount.\n",
    "\n",
    "**Note**: For additional information about the attributes used, please look up the file `dataset_4_description.txt`. This files also contains details of attributes that have been omitted from the data set.\n",
    "\n",
    "### Part (a): Fit regression model\n",
    "Build a suitable model to predict the donation amount. How good is your model? \n",
    "\n",
    "\n",
    "### Part (b): Evaluate the total profit of the fitted model\n",
    "Suppose you are told that the cost of mailing the donor is \\$7. Use your model to maximize profit. Implement, explain and rigorously justify your strategy. How does your strategry compare with blanket mailing everyone.\n",
    "\n",
    "### Part (c): Further Discussion\n",
    "In hindsight, thoroughly discuss the appropriatenes of using a regression model for this dataset (you must at least address the suitability with respect to profit maximization and model assumptions). Rigorously justify your reasoning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
