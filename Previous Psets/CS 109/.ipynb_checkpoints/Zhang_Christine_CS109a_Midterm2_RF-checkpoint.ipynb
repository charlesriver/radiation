{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Midterm 2\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Tuesday, November 22nd, 2016 at 12:00pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Diagnosing the Semian Flu 2016\n",
    "\n",
    "You are given the early data for an outbreak of a dangerous virus originating from a group of primates being keeped in a Massechussetts biomedical research lab, this virus is dubbed the \"Semian Flu\".\n",
    "\n",
    "You have the medical records of $n$ number of patients in `'flu_train.csv`. There are two general types of patients in the data, flu patients and healthy (this is recorded in the column labeled `flu`, a 0 indicates the absences of the virus and a 1 indicates presence). Furthermore, scientists have found that there are two strains of the virus, each requiring a different type of treatment (this is recorded in the column labeled `flutype`, a 1 indicates the absences of the virus, a 2 indicates presence of strain 1 and a 3 indicates the presence of strain 2).\n",
    "\n",
    "**Your task:** build a model to predict if a given patient has the flu. Your goal is to catch as many flu patients as possible without misdiagnosing too many healthy patients.\n",
    "\n",
    "**The deliverable:** a function called `flu_predict` which satisfies:\n",
    "\n",
    "- input: `x_test`, a set of medical predictors for a group of patients\n",
    "- output: `y_pred`, a set of labels, one for each patient; 0 for healthy and 1 for infected with the flu virus\n",
    "\n",
    "The MA state government will use your model to diagnose sets of future patients (held by us). You can expect that there will be an increase in the number of flu patients in any groups of patients in the future.\n",
    "\n",
    "We provide you with some benchmarks for comparison.\n",
    "\n",
    "**Baseline Model:** \n",
    "- ~50% expected accuracy on healthy patients in observed data\n",
    "- ~50% expected accuracy on flu patients in observed data\n",
    "- ~50% expected accuracy on healthy patients in future data \n",
    "- ~50% expected accuracy on flu patients in future data\n",
    "- time to build: 5 min\n",
    "\n",
    "**Reasonable Model:** \n",
    "- ~69% expected accuracy on healthy patients in observed data\n",
    "- ~55% expected accuracy on flu patients, in observed data\n",
    "- ~69% expected accuracy on healthy patients in future data\n",
    "- ~60% expected accuracy on flu patients, in future data\n",
    "- time to build: 20 min\n",
    "\n",
    "**Grading:**\n",
    "Your grade will be based on:\n",
    "1. your model's ability to out-perform our benchmarks\n",
    "2. your ability to carefully and thoroughly follow the data science pipeline (see lecture slides for definition)\n",
    "3. the extend to which all choices are reasonable and defensible by methods you have learned in this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to clean the dataset. I accomplished this through a series of steps after uploading the csvs.\n",
    "1. I made sure all types were either float64 or object. This was accomplished by iterating and finding all columns with type int64 and using .astype to alter them as floats. \n",
    "2. Next, I made sure all object types were categorical. This was correct so I did not have to manually change more to type float64.\n",
    "3. I noticed that race3 and race1 were very similiar except race1 did not include asians but rather labeled them as other. I combined columns race1 and race3 but encoding asians in race1. This was accomplished by creating a for loop and for every instance of asian in race3, I altered the corresponding race1 cell.  \n",
    "4. Next I dropped columns with duplicate information. There are 3 columns for age and 2 for income so I dropped the excess information. ID is also not informative in predicting disease (no correlation) so I dropped it as well.\n",
    "5. There are a lot of entries with NaN because no value is entered. I dropped columns with more than 50% NaNs because there is not enough data to get a fair estimate through imputation. \n",
    "6. With the remaining columns, I replaced all NaNs for categorical columns with the mode (most frequent entry) and I replaced all NaNs for quantitative columns with the median. \n",
    "7. Lastly, I one hot the categorical variables to be able to start testing my models. \n",
    "\n",
    "I created a random model that randomly predicts 0 or 1. This gives me a correct classification accuracy of ~50% for both class 0 and class 1. \n",
    "\n",
    "I then tuned a few parameters for decision trees and KNN to establish a quick tuning baseline. I then tested 10 different models:\n",
    "1. KNN\n",
    "2. Unweighted logistic regression\n",
    "3. Unweighted logistic quadratic regression\n",
    "4. Weighted logistic regression\n",
    "5. Weighted quad logistic regression\n",
    "6. LDA\n",
    "7. QDA\n",
    "8. Decision Tree\n",
    "9. Random Forest\n",
    "10. SVM\n",
    "\n",
    "Weighted logistic regression ended up with the highest hollistic accuracy. It has the highest joint accuracy on both accuracy on class 0 and class 1 with 75% and 57% respectively. Even though the overall accuracy wasn't the highest, it had the highest on class 1, which is the hardest to predict since there are so few entries. Thus, I rather chose weighted logistic regression over a model with 0.99 overall accuracy but 0.1 accuracy on class 1. These flawed models are predicting that almost all patients are healthy and since the number of healthy individuals is ~10x the number of diseased individuals in this dataset, these models are not discerning between 0 and 1 in detail while still getting a high overall accuracy. Using weighted logistic regression will allow us to have the most accurate predictions on both classes. \n",
    "\n",
    "Finally, I concatenated IDs and final predictions together to export into CSV format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (5246, 76)\n",
      "Testing dataset shape:  (1533, 74)\n"
     ]
    }
   ],
   "source": [
    "# import training dataset\n",
    "data_train = pd.read_csv('flu_train.csv')\n",
    "data_train_id = data_train['ID']\n",
    "data_train_flu = data_train['flu']\n",
    "print 'Training dataset shape: ', data_train.shape\n",
    "\n",
    "# import testing dataset\n",
    "data_test = pd.read_csv('flu_test_no_y.csv')\n",
    "data_test_id = data_test['ID']\n",
    "print 'Testing dataset shape: ', data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeDecade</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Race3</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncome</th>\n",
       "      <th>...</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SexNumPartYear</th>\n",
       "      <th>SameSex</th>\n",
       "      <th>SexOrientation</th>\n",
       "      <th>PregnantNow</th>\n",
       "      <th>flu</th>\n",
       "      <th>flutype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51624</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>30-39</td>\n",
       "      <td>409.0</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>25000-34999</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>female</td>\n",
       "      <td>49</td>\n",
       "      <td>40-49</td>\n",
       "      <td>596.0</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some College</td>\n",
       "      <td>LivePartner</td>\n",
       "      <td>35000-44999</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51638</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>0-9</td>\n",
       "      <td>115.0</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75000-99999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51646</td>\n",
       "      <td>male</td>\n",
       "      <td>8</td>\n",
       "      <td>0-9</td>\n",
       "      <td>101.0</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55000-64999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51647</td>\n",
       "      <td>female</td>\n",
       "      <td>45</td>\n",
       "      <td>40-49</td>\n",
       "      <td>541.0</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College Grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>75000-99999</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bisexual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Gender  Age AgeDecade  AgeMonths  Race1 Race3     Education  \\\n",
       "0  51624    male   34     30-39      409.0  White   NaN   High School   \n",
       "1  51630  female   49     40-49      596.0  White   NaN  Some College   \n",
       "2  51638    male    9       0-9      115.0  White   NaN           NaN   \n",
       "3  51646    male    8       0-9      101.0  White   NaN           NaN   \n",
       "4  51647  female   45     40-49      541.0  White   NaN  College Grad   \n",
       "\n",
       "  MaritalStatus     HHIncome   ...     HardDrugs  SexEver  SexAge  \\\n",
       "0       Married  25000-34999   ...           Yes      Yes    16.0   \n",
       "1   LivePartner  35000-44999   ...           Yes      Yes    12.0   \n",
       "2           NaN  75000-99999   ...           NaN      NaN     NaN   \n",
       "3           NaN  55000-64999   ...           NaN      NaN     NaN   \n",
       "4       Married  75000-99999   ...            No      Yes    13.0   \n",
       "\n",
       "  SexNumPartnLife SexNumPartYear  SameSex  SexOrientation  PregnantNow  flu  \\\n",
       "0             8.0            1.0       No    Heterosexual          NaN    0   \n",
       "1            10.0            1.0      Yes    Heterosexual          NaN    0   \n",
       "2             NaN            NaN      NaN             NaN          NaN    0   \n",
       "3             NaN            NaN      NaN             NaN          NaN    0   \n",
       "4            20.0            0.0      Yes        Bisexual          NaN    0   \n",
       "\n",
       "   flutype  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 5 rows of dataset\n",
    "data_train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset floats: \n",
      "ID\n",
      "Age\n",
      "flu\n",
      "flutype\n",
      "\n",
      "Testing dataset floats: \n",
      "ID\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "# find training dataset entries with int type\n",
    "print 'Training dataset floats: '\n",
    "for y in data_train.columns:\n",
    "    if(data_train[y].dtype == np.int64):\n",
    "          print y\n",
    "            \n",
    "# find testing dataset entries with int type\n",
    "print '\\n', 'Testing dataset floats: '\n",
    "for y in data_test.columns:\n",
    "    if(data_test[y].dtype == np.int64):\n",
    "          print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make arrays of columsn with floats (determined above)\n",
    "to_float_train = ['Age', 'ID', 'flu', 'flutype']\n",
    "to_float_test = ['Age', 'ID']\n",
    "\n",
    "# Converted columns to floating point for training and test set\n",
    "for feature_name in to_float_train:\n",
    "    data_train[feature_name] = data_train[feature_name].astype(float)\n",
    "\n",
    "for feature_name in to_float_test:\n",
    "    data_test[feature_name] = data_test[feature_name].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeDecade</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Race3</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncome</th>\n",
       "      <th>HomeOwn</th>\n",
       "      <th>Work</th>\n",
       "      <th>BMICatUnder20yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>SmokeNow</th>\n",
       "      <th>Smoke100</th>\n",
       "      <th>Smoke100n</th>\n",
       "      <th>Marijuana</th>\n",
       "      <th>RegularMarij</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SameSex</th>\n",
       "      <th>SexOrientation</th>\n",
       "      <th>PregnantNow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>30-39</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>25000-34999</td>\n",
       "      <td>Own</td>\n",
       "      <td>NotWorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Smoker</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>40-49</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some College</td>\n",
       "      <td>LivePartner</td>\n",
       "      <td>35000-44999</td>\n",
       "      <td>Rent</td>\n",
       "      <td>NotWorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Smoker</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0-9</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75000-99999</td>\n",
       "      <td>Rent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>0-9</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55000-64999</td>\n",
       "      <td>Own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>40-49</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College Grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>75000-99999</td>\n",
       "      <td>Own</td>\n",
       "      <td>Working</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bisexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender AgeDecade  Race1 Race3     Education MaritalStatus     HHIncome  \\\n",
       "0    male     30-39  White   NaN   High School       Married  25000-34999   \n",
       "1  female     40-49  White   NaN  Some College   LivePartner  35000-44999   \n",
       "2    male       0-9  White   NaN           NaN           NaN  75000-99999   \n",
       "3    male       0-9  White   NaN           NaN           NaN  55000-64999   \n",
       "4  female     40-49  White   NaN  College Grad       Married  75000-99999   \n",
       "\n",
       "  HomeOwn        Work BMICatUnder20yrs     ...     SmokeNow Smoke100  \\\n",
       "0     Own  NotWorking              NaN     ...           No      Yes   \n",
       "1    Rent  NotWorking              NaN     ...          Yes      Yes   \n",
       "2    Rent         NaN              NaN     ...          NaN      NaN   \n",
       "3     Own         NaN              NaN     ...          NaN      NaN   \n",
       "4     Own     Working              NaN     ...          NaN       No   \n",
       "\n",
       "    Smoke100n Marijuana RegularMarij HardDrugs SexEver SameSex SexOrientation  \\\n",
       "0      Smoker       Yes           No       Yes     Yes      No   Heterosexual   \n",
       "1      Smoker       Yes           No       Yes     Yes     Yes   Heterosexual   \n",
       "2         NaN       NaN          NaN       NaN     NaN     NaN            NaN   \n",
       "3         NaN       NaN          NaN       NaN     NaN     NaN            NaN   \n",
       "4  Non-Smoker       Yes           No        No     Yes     Yes       Bisexual   \n",
       "\n",
       "  PregnantNow  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that object types are all categorical\n",
    "object_columns = []\n",
    "for y in data_train.columns:\n",
    "    if(data_train[y].dtype == np.object):\n",
    "          object_columns.append(y)\n",
    "data_train[object_columns].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Christine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Christine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# combine race1 and race3 (move 'asian' over as a race1 category)\n",
    "for (num, entry) in enumerate(data_train['Race3']):\n",
    "    if entry == \"Asian\":\n",
    "        data_train['Race1'][num] = \"Asian\"\n",
    "\n",
    "for (num, entry) in enumerate(data_test['Race3']):\n",
    "    if entry == \"Asian\":\n",
    "        data_test['Race1'][num] = \"Asian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>HomeOwn</th>\n",
       "      <th>Work</th>\n",
       "      <th>...</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SexNumPartYear</th>\n",
       "      <th>SameSex</th>\n",
       "      <th>SexOrientation</th>\n",
       "      <th>PregnantNow</th>\n",
       "      <th>flu</th>\n",
       "      <th>flutype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>White</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>NotWorking</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Some College</td>\n",
       "      <td>LivePartner</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Rent</td>\n",
       "      <td>NotWorking</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>White</td>\n",
       "      <td>College Grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>Working</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bisexual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Race1     Education MaritalStatus  HHIncomeMid  Poverty  \\\n",
       "0    male  34.0  White   High School       Married      30000.0     1.36   \n",
       "1  female  49.0  White  Some College   LivePartner      40000.0     1.91   \n",
       "2    male   9.0  White           NaN           NaN      87500.0     1.84   \n",
       "3    male   8.0  White           NaN           NaN      60000.0     2.33   \n",
       "4  female  45.0  White  College Grad       Married      87500.0     5.00   \n",
       "\n",
       "   HomeRooms HomeOwn        Work   ...     HardDrugs  SexEver  SexAge  \\\n",
       "0        6.0     Own  NotWorking   ...           Yes      Yes    16.0   \n",
       "1        5.0    Rent  NotWorking   ...           Yes      Yes    12.0   \n",
       "2        6.0    Rent         NaN   ...           NaN      NaN     NaN   \n",
       "3        7.0     Own         NaN   ...           NaN      NaN     NaN   \n",
       "4        6.0     Own     Working   ...            No      Yes    13.0   \n",
       "\n",
       "   SexNumPartnLife  SexNumPartYear SameSex SexOrientation  PregnantNow  flu  \\\n",
       "0              8.0             1.0      No   Heterosexual          NaN  0.0   \n",
       "1             10.0             1.0     Yes   Heterosexual          NaN  0.0   \n",
       "2              NaN             NaN     NaN            NaN          NaN  0.0   \n",
       "3              NaN             NaN     NaN            NaN          NaN  0.0   \n",
       "4             20.0             0.0     Yes       Bisexual          NaN  0.0   \n",
       "\n",
       "   flutype  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns that store repeated information (age, income, and race) and uninformative information (ID)\n",
    "data_train = data_train.drop(['ID', 'AgeDecade', 'AgeMonths', 'HHIncome', 'Race3'], 1)\n",
    "data_test = data_test.drop(['ID', 'AgeDecade', 'AgeMonths', 'HHIncome', 'Race3'], 1)\n",
    "\n",
    "data_train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Education',\n",
       " 'MaritalStatus',\n",
       " 'HHIncomeMid',\n",
       " 'Poverty',\n",
       " 'HomeRooms',\n",
       " 'HomeOwn',\n",
       " 'Work',\n",
       " 'Weight',\n",
       " 'Length',\n",
       " 'HeadCirc',\n",
       " 'Height',\n",
       " 'BMI',\n",
       " 'BMICatUnder20yrs',\n",
       " 'BMI_WHO',\n",
       " 'Pulse',\n",
       " 'BPSysAve',\n",
       " 'BPDiaAve',\n",
       " 'BPSys1',\n",
       " 'BPDia1',\n",
       " 'BPSys2',\n",
       " 'BPDia2',\n",
       " 'BPSys3',\n",
       " 'BPDia3',\n",
       " 'Testosterone',\n",
       " 'DirectChol',\n",
       " 'TotChol',\n",
       " 'UrineVol1',\n",
       " 'UrineFlow1',\n",
       " 'UrineVol2',\n",
       " 'UrineFlow2',\n",
       " 'Diabetes',\n",
       " 'DiabetesAge',\n",
       " 'HealthGen',\n",
       " 'DaysMentHlthBad',\n",
       " 'LittleInterest',\n",
       " 'Depressed',\n",
       " 'nPregnancies',\n",
       " 'nBabies',\n",
       " 'Age1stBaby',\n",
       " 'SleepHrsNight',\n",
       " 'SleepTrouble',\n",
       " 'PhysActive',\n",
       " 'PhysActiveDays',\n",
       " 'TVHrsDay',\n",
       " 'CompHrsDay',\n",
       " 'TVHrsDayChild',\n",
       " 'CompHrsDayChild',\n",
       " 'Alcohol12PlusYr',\n",
       " 'AlcoholDay',\n",
       " 'AlcoholYear',\n",
       " 'SmokeNow',\n",
       " 'Smoke100',\n",
       " 'Smoke100n',\n",
       " 'SmokeAge',\n",
       " 'Marijuana',\n",
       " 'AgeFirstMarij',\n",
       " 'RegularMarij',\n",
       " 'AgeRegMarij',\n",
       " 'HardDrugs',\n",
       " 'SexEver',\n",
       " 'SexAge',\n",
       " 'SexNumPartnLife',\n",
       " 'SexNumPartYear',\n",
       " 'SameSex',\n",
       " 'SexOrientation',\n",
       " 'PregnantNow']"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find columns with missing values \n",
    "pd.isnull(data_train).any()\n",
    "data_train.columns[pd.isnull(data_train).any()].tolist()\n",
    "data_test.columns[pd.isnull(data_train).any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender 0.0\n",
      "Age 0.0\n",
      "Race1 0.0\n",
      "Education 0.32\n",
      "MaritalStatus 0.32\n",
      "HHIncomeMid 0.09\n",
      "Poverty 0.08\n",
      "HomeRooms 0.01\n",
      "HomeOwn 0.01\n",
      "Work 0.26\n",
      "Weight 0.01\n",
      "Height 0.04\n",
      "BMI 0.04\n",
      "BMI_WHO 0.05\n",
      "Pulse 0.17\n",
      "BPSysAve 0.17\n",
      "BPDiaAve 0.17\n",
      "BPSys1 0.2\n",
      "BPDia1 0.2\n",
      "BPSys2 0.19\n",
      "BPDia2 0.19\n",
      "BPSys3 0.19\n",
      "BPDia3 0.19\n",
      "DirectChol 0.17\n",
      "TotChol 0.17\n",
      "UrineVol1 0.12\n",
      "UrineFlow1 0.18\n",
      "Diabetes 0.02\n",
      "HealthGen 0.28\n",
      "DaysMentHlthBad 0.28\n",
      "LittleInterest 0.37\n",
      "Depressed 0.37\n",
      "SleepHrsNight 0.26\n",
      "SleepTrouble 0.26\n",
      "PhysActive 0.2\n",
      "Alcohol12PlusYr 0.38\n",
      "AlcoholYear 0.45\n",
      "Smoke100 0.32\n",
      "Smoke100n 0.32\n",
      "HardDrugs 0.47\n",
      "SexEver 0.47\n",
      "SexAge 0.49\n",
      "SexNumPartnLife 0.47\n",
      "SameSex 0.47\n",
      "flu 0.0\n",
      "flutype 0.0\n",
      "Gender 0.0\n",
      "Age 0.0\n",
      "Race1 0.0\n",
      "Education 0.3\n",
      "MaritalStatus 0.3\n",
      "HHIncomeMid 0.09\n",
      "Poverty 0.08\n",
      "HomeRooms 0.01\n",
      "HomeOwn 0.01\n",
      "Work 0.25\n",
      "Weight 0.01\n",
      "Height 0.04\n",
      "BMI 0.04\n",
      "BMI_WHO 0.05\n",
      "Pulse 0.17\n",
      "BPSysAve 0.17\n",
      "BPDiaAve 0.17\n",
      "BPSys1 0.21\n",
      "BPDia1 0.21\n",
      "BPSys2 0.19\n",
      "BPDia2 0.19\n",
      "BPSys3 0.19\n",
      "BPDia3 0.19\n",
      "DirectChol 0.18\n",
      "TotChol 0.18\n",
      "UrineVol1 0.12\n",
      "UrineFlow1 0.18\n",
      "Diabetes 0.02\n",
      "HealthGen 0.27\n",
      "DaysMentHlthBad 0.27\n",
      "LittleInterest 0.36\n",
      "Depressed 0.36\n",
      "SleepHrsNight 0.25\n",
      "SleepTrouble 0.25\n",
      "PhysActive 0.19\n",
      "Alcohol12PlusYr 0.37\n",
      "AlcoholYear 0.45\n",
      "Smoke100 0.3\n",
      "Smoke100n 0.3\n",
      "HardDrugs 0.47\n",
      "SexEver 0.47\n",
      "SexAge 0.49\n",
      "SexNumPartnLife 0.47\n",
      "SameSex 0.47\n"
     ]
    }
   ],
   "source": [
    "# count number of nans in each array\n",
    "nan_array_train = []\n",
    "for y in data_train.columns:\n",
    "    number_nans = np.count_nonzero(pd.isnull(data_train[y]))\n",
    "    ratio = float(number_nans) / float(data_train.shape[0])\n",
    "    # remove column if more than 50% nans\n",
    "    if ratio <= 0.5:\n",
    "        nan_array_train.append(y)\n",
    "        print y, round(ratio, 2)\n",
    "\n",
    "# count number of nans in each array\n",
    "nan_array_test = []\n",
    "for y in data_test.columns:\n",
    "    number_nans = np.count_nonzero(pd.isnull(data_test[y]))\n",
    "    ratio = float(number_nans) / float(data_test.shape[0])\n",
    "    # remove column if more than 50% nans\n",
    "    if ratio <= 0.5:\n",
    "        nan_array_test.append(y)\n",
    "        print y, round(ratio, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new dataset with only populated columns\n",
    "data_train = data_train[nan_array_train]\n",
    "data_test = data_test[nan_array_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data by removing \"nan\" entries to conduct one-hot encoding. Nans for categorical variables can be replaced with the mode, most common entry. Nans for quantitative variables can be replaced with the median value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female',\n",
       " 36.0,\n",
       " 'White',\n",
       " 'Some College',\n",
       " 'Married',\n",
       " 50000.0,\n",
       " 2.27,\n",
       " 6.0,\n",
       " 'Own',\n",
       " 'Working',\n",
       " 72.7,\n",
       " 165.2,\n",
       " 26.31,\n",
       " '30.0_plus',\n",
       " 74.0,\n",
       " 116.0,\n",
       " 68.0,\n",
       " 118.0,\n",
       " 68.0,\n",
       " 116.0,\n",
       " 68.0,\n",
       " 116.0,\n",
       " 68.0,\n",
       " 1.29,\n",
       " 4.76,\n",
       " 93.0,\n",
       " 0.69,\n",
       " 'No',\n",
       " 'Good',\n",
       " 0.0,\n",
       " 'None',\n",
       " 'None',\n",
       " 7.0,\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 24.0,\n",
       " 'No',\n",
       " 'Non-Smoker',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 17.0,\n",
       " 5.0,\n",
       " 'No']"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replace_train = []\n",
    "for each in nan_array_train:\n",
    "    data_nonan = data_train[each].dropna()\n",
    "    # replace float values with the median\n",
    "    if data_nonan.dtype == np.float64:\n",
    "        to_replace_train.append(round(np.median(data_nonan),2))\n",
    "    # replace categorical variables with the most common entry\n",
    "    if data_nonan.dtype == np.object:\n",
    "        items_counts = data_nonan.value_counts()\n",
    "        max_item = items_counts.idxmax()\n",
    "        to_replace_train.append(max_item)\n",
    "\n",
    "to_replace_test = []\n",
    "for each in nan_array_test:\n",
    "    data_nonan = data_test[each].dropna()\n",
    "    # replace float values with the median\n",
    "    if data_nonan.dtype == np.float64:\n",
    "        to_replace_test.append(round(np.median(data_nonan),2))\n",
    "    # replace categorical variables with the most common entry\n",
    "    if data_nonan.dtype == np.object:\n",
    "        items_counts = data_nonan.value_counts()\n",
    "        max_item = items_counts.idxmax()\n",
    "        to_replace_test.append(max_item)\n",
    "to_replace_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>HomeOwn</th>\n",
       "      <th>Work</th>\n",
       "      <th>...</th>\n",
       "      <th>PhysActive</th>\n",
       "      <th>Alcohol12PlusYr</th>\n",
       "      <th>AlcoholYear</th>\n",
       "      <th>Smoke100</th>\n",
       "      <th>Smoke100n</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SameSex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Some College</td>\n",
       "      <td>Married</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>Working</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>White</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>Working</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Smoker</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Some College</td>\n",
       "      <td>Married</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>Working</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Some College</td>\n",
       "      <td>Married</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>Working</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>8th Grade</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Rent</td>\n",
       "      <td>NotWorking</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Race1     Education MaritalStatus  HHIncomeMid  Poverty  \\\n",
       "0    male   4.0  Other  Some College       Married      22500.0     1.07   \n",
       "1    male  60.0  White   High School       Married      17500.0     1.03   \n",
       "2    male  38.0  White  Some College       Married      22500.0     1.15   \n",
       "3    male   8.0  White  Some College       Married      70000.0     3.55   \n",
       "4  female  59.0  Other     8th Grade       Widowed      22500.0     1.37   \n",
       "\n",
       "   HomeRooms HomeOwn        Work   ...     PhysActive  Alcohol12PlusYr  \\\n",
       "0        9.0     Own     Working   ...            Yes              Yes   \n",
       "1        5.0     Own     Working   ...             No              Yes   \n",
       "2        6.0     Own     Working   ...             No               No   \n",
       "3        5.0     Own     Working   ...            Yes              Yes   \n",
       "4        4.0    Rent  NotWorking   ...             No              Yes   \n",
       "\n",
       "   AlcoholYear Smoke100   Smoke100n  HardDrugs  SexEver  SexAge  \\\n",
       "0         24.0       No  Non-Smoker         No      Yes    17.0   \n",
       "1         36.0      Yes      Smoker         No      Yes    20.0   \n",
       "2          0.0       No  Non-Smoker         No      Yes    23.0   \n",
       "3         24.0       No  Non-Smoker         No      Yes    17.0   \n",
       "4         24.0       No  Non-Smoker         No      Yes    17.0   \n",
       "\n",
       "   SexNumPartnLife  SameSex  \n",
       "0              5.0       No  \n",
       "1              1.0       No  \n",
       "2              1.0       No  \n",
       "3              5.0       No  \n",
       "4              5.0       No  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace nans in training dataframe with median/mode\n",
    "counter = 0\n",
    "for each in data_train:\n",
    "    data_train[each] = data_train[each].fillna(to_replace[counter])\n",
    "    counter = counter + 1\n",
    "\n",
    "# replace nans in testing dataframe with median/mode\n",
    "counter = 0\n",
    "for each in data_test:\n",
    "    data_test[each] = data_test[each].fillna(to_replace[counter])\n",
    "    counter = counter + 1\n",
    "\n",
    "data_test.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>HomeOwn</th>\n",
       "      <th>Work</th>\n",
       "      <th>...</th>\n",
       "      <th>PhysActive</th>\n",
       "      <th>Alcohol12PlusYr</th>\n",
       "      <th>AlcoholYear</th>\n",
       "      <th>Smoke100</th>\n",
       "      <th>Smoke100n</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SameSex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Race1  Education  MaritalStatus  HHIncomeMid  Poverty  \\\n",
       "0       1   4.0      4          4              2      22500.0     1.07   \n",
       "1       1  60.0      5          3              2      17500.0     1.03   \n",
       "2       1  38.0      5          4              2      22500.0     1.15   \n",
       "3       1   8.0      5          4              2      70000.0     3.55   \n",
       "4       0  59.0      4          0              5      22500.0     1.37   \n",
       "\n",
       "   HomeRooms  HomeOwn  Work   ...     PhysActive  Alcohol12PlusYr  \\\n",
       "0        9.0        1     2   ...              1                1   \n",
       "1        5.0        1     2   ...              0                1   \n",
       "2        6.0        1     2   ...              0                0   \n",
       "3        5.0        1     2   ...              1                1   \n",
       "4        4.0        2     1   ...              0                1   \n",
       "\n",
       "   AlcoholYear  Smoke100  Smoke100n  HardDrugs  SexEver  SexAge  \\\n",
       "0         24.0         0          0          0        1    17.0   \n",
       "1         36.0         1          1          0        1    20.0   \n",
       "2          0.0         0          0          0        1    23.0   \n",
       "3         24.0         0          0          0        1    17.0   \n",
       "4         24.0         0          0          0        1    17.0   \n",
       "\n",
       "   SexNumPartnLife  SameSex  \n",
       "0              5.0        0  \n",
       "1              1.0        0  \n",
       "2              1.0        0  \n",
       "3              5.0        0  \n",
       "4              5.0        0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode categorical variables\n",
    "def encode_categorical(array):\n",
    "    if not array.dtype == np.dtype('float64'):\n",
    "        return preprocessing.LabelEncoder().fit_transform(array) \n",
    "    else:\n",
    "        return array\n",
    "    \n",
    "# Categorical columns for use in one-hot encoder\n",
    "categorical = (data_train.dtypes.values != np.dtype('float64'))\n",
    "\n",
    "# Encode all labels\n",
    "data_train = data_train.apply(encode_categorical)\n",
    "\n",
    "def encode_categorical(array):\n",
    "    if not array.dtype == np.dtype('float64'):\n",
    "        return preprocessing.LabelEncoder().fit_transform(array) \n",
    "    else:\n",
    "        return array\n",
    "    \n",
    "# Categorical columns for use in one-hot encoder\n",
    "categorical = (data_train.dtypes.values != np.dtype('float64'))\n",
    "data_test = data_test.apply(encode_categorical)\n",
    "\n",
    "# Get numpy array from data\n",
    "x = data_train.values[:, :-2]\n",
    "y = data_train.values[:, -2]\n",
    "\n",
    "# Apply one hot endcoing\n",
    "encoder = preprocessing.OneHotEncoder(categorical_features=categorical[:-2], sparse=False)  # Last value in mask is y\n",
    "x = encoder.fit_transform(x)\n",
    "\n",
    "x_testing = data_test.values\n",
    "encoder = preprocessing.OneHotEncoder(categorical_features=categorical, sparse=False)  # Last value in mask is y\n",
    "x_testing = encoder.fit_transform(x_testing)\n",
    "data_test.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into testing and training sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for computing the accuracy a given model on the entire test set, the accuracy on class 0 in the test set\n",
    "#and the accuracy on class 1\n",
    "score = lambda model, x_test, y_test: pd.Series([model.score(x_test, y_test), \n",
    "                                                 model.score(x_test[y_test==0], y_test[y_test==0]),\n",
    "                                                 model.score(x_test[y_test==1], y_test[y_test==1])],\n",
    "                                                index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create random model that predicts 0 or 1\n",
    "class Random_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.random.randint(0, 2, len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# call random model on testing set\n",
    "random_model = Random_model()\n",
    "random_model_scores = score(random_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td>0.511753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 0</th>\n",
       "      <td>0.509109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 1</th>\n",
       "      <td>0.538043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     random model\n",
       "overall accuracy         0.511753\n",
       "accuracy on class 0      0.509109\n",
       "accuracy on class 1      0.538043"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({'random model': random_model_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 2 Accuracy: 0.961813842482\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5f8BQL5ZhIfnonUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118a6cb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tune tree for best depth\n",
    "depths = range(1, 20)\n",
    "kf = KFold(len(x_train), n_folds=5)\n",
    "tree_score_array = []\n",
    "\n",
    "for depth in depths:\n",
    "    # use CV to optimize tree length\n",
    "    for train_index, test_index in kf:\n",
    "        tree_score_inner, knn_score_inner = [], []\n",
    "        x_validate_train, x_validate_test = x_train[train_index], x_train[test_index]\n",
    "        y_validate_train, y_validate_test = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        tree = DecisionTree(max_depth=depth)\n",
    "        tree.fit(x_validate_train, y_validate_train)\n",
    "        tree_score_inner.append(tree.score(x_validate_test, y_validate_test))\n",
    "        \n",
    "    tree_score_array.append(np.mean(tree_score_inner))\n",
    "\n",
    "# determine maximum tree value and index\n",
    "tree_score_max = np.max(tree_score_array)\n",
    "tree_best_depth = np.argmax(tree_score_array) + 1\n",
    "\n",
    "# plot and label axes\n",
    "plt.plot(depths, tree_score_array)\n",
    "plt.title(\"Accuracy for Various Depths in Decision Trees\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "print 'Best depth: {} Accuracy: {}'.format(tree_best_depth, tree_score_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neighbors: 10 Accuracy: 0.941550190597\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGpslsx5opAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118c8ed90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tune knn for best number of neighbors\n",
    "depths = range(1, 20)\n",
    "knn_score_array = []\n",
    "\n",
    "for depth in depths:\n",
    "    # fit knn and score\n",
    "    knn = KNN(n_neighbors=depth)\n",
    "    knn.fit(x_train, y_train)\n",
    "    knn_score = knn.score(x_test, y_test)\n",
    "    knn_score_array.append(knn_score)\n",
    "\n",
    "# calculate accuracy and plot\n",
    "knn_score_max = np.max(knn_score_array)\n",
    "knn_best_depth = np.argmax(knn_score_array) + 1\n",
    "plt.plot(depths, knn_score_array)\n",
    "plt.title(\"Accuracy for Various Number of Neighbors in KNN\")\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "print 'Best number of neighbors: {} Accuracy: {}'.format(knn_best_depth, knn_score_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNN(n_neighbors=knn_best_depth)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_scores = score(knn, x_test, y_test)\n",
    "\n",
    "#Unweighted logistic regression\n",
    "unweighted_logistic = LogisticRegression()\n",
    "unweighted_logistic.fit(x_train, y_train)\n",
    "unweighted_log_scores = score(unweighted_logistic, x_test, y_test)\n",
    "\n",
    "#Unweighted logistic quadratic regression\n",
    "unweighted_logistic_poly = LogisticRegression()\n",
    "\n",
    "#Expand our predictor array with quadratic terms\n",
    "quad_features = preprocessing.PolynomialFeatures(degree = 2)\n",
    "x_expanded_train = quad_features.fit_transform(x_train)\n",
    "x_expanded_test = quad_features.fit_transform(x_test)\n",
    "\n",
    "unweighted_logistic_poly.fit(x_expanded_train, y_train)\n",
    "unweighted_log_poly_scores = score(unweighted_logistic_poly, x_expanded_test, y_test)\n",
    "\n",
    "#Weighted logistic regression\n",
    "weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "weighted_logistic.fit(x_train, y_train)\n",
    "weighted_log_scores = score(weighted_logistic, x_test, y_test)\n",
    "\n",
    "#Weighted quad logistic regression\n",
    "weighted_logistic_poly = LogisticRegression(class_weight='balanced')\n",
    "#Expand our predictor array with quadratic terms\n",
    "quad_features = preprocessing.PolynomialFeatures(degree = 2)\n",
    "x_expanded_train = quad_features.fit_transform(x_train)\n",
    "x_expanded_test = quad_features.fit_transform(x_test)\n",
    "\n",
    "weighted_logistic_poly.fit(x_expanded_train, y_train)\n",
    "weighted_log_poly_scores = score(weighted_logistic_poly, x_expanded_test, y_test)\n",
    "\n",
    "#LDA\n",
    "lda = LDA()\n",
    "lda.fit(x_train, y_train)\n",
    "lda_scores = score(lda, x_test, y_test)\n",
    "\n",
    "#QDA\n",
    "qda = QDA()\n",
    "qda.fit(x_train, y_train)\n",
    "qda_scores = score(qda, x_test, y_test)\n",
    "\n",
    "#Decision Tree\n",
    "tree = DecisionTree(max_depth=tree_best_depth)\n",
    "tree.fit(x_train, y_train)\n",
    "tree_scores = score(tree, x_test, y_test)\n",
    "\n",
    "#Random Forest\n",
    "rf = RandomForest()\n",
    "rf.fit(x_train, y_train)\n",
    "rf_scores = score(rf, x_test, y_test)\n",
    "\n",
    "#SVM\n",
    "svm = SVC(C=svm_best_depth, kernel='linear', class_weight='balanced')\n",
    "svm.fit(x_train[1:100], y_train[1:100])\n",
    "svm_scores = score(svm, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>lda</th>\n",
       "      <th>qda</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "      <th>unweighted logistic</th>\n",
       "      <th>unweighted quad logistic</th>\n",
       "      <th>weighted logistic</th>\n",
       "      <th>weighted quad logistic</th>\n",
       "      <th>weighted svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td>0.94155</td>\n",
       "      <td>0.938374</td>\n",
       "      <td>0.839581</td>\n",
       "      <td>0.942186</td>\n",
       "      <td>0.944727</td>\n",
       "      <td>0.940915</td>\n",
       "      <td>0.939644</td>\n",
       "      <td>0.739517</td>\n",
       "      <td>0.696633</td>\n",
       "      <td>0.825921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.983131</td>\n",
       "      <td>0.874494</td>\n",
       "      <td>0.997638</td>\n",
       "      <td>0.997638</td>\n",
       "      <td>0.997301</td>\n",
       "      <td>0.997976</td>\n",
       "      <td>0.749663</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.870445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.277174</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.092391</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576087</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         knn       lda       qda        rf      tree  \\\n",
       "overall accuracy     0.94155  0.938374  0.839581  0.942186  0.944727   \n",
       "accuracy on class 0  1.00000  0.983131  0.874494  0.997638  0.997638   \n",
       "accuracy on class 1  0.00000  0.217391  0.277174  0.048913  0.092391   \n",
       "\n",
       "                     unweighted logistic  unweighted quad logistic  \\\n",
       "overall accuracy                0.940915                  0.939644   \n",
       "accuracy on class 0             0.997301                  0.997976   \n",
       "accuracy on class 1             0.032609                  0.000000   \n",
       "\n",
       "                     weighted logistic  weighted quad logistic  weighted svm  \n",
       "overall accuracy              0.739517                0.696633      0.825921  \n",
       "accuracy on class 0           0.749663                0.705466      0.870445  \n",
       "accuracy on class 1           0.576087                0.554348      0.108696  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({'knn': knn_scores, \n",
    "                         'unweighted logistic': unweighted_log_scores,\n",
    "                         'unweighted quad logistic': unweighted_log_poly_scores,\n",
    "                         'weighted logistic': weighted_log_scores,\n",
    "                         'weighted quad logistic': weighted_log_poly_scores,\n",
    "                         'lda': lda_scores,\n",
    "                         'qda': qda_scores,\n",
    "                         'tree': tree_scores,\n",
    "                         'rf': rf_scores,\n",
    "                         'weighted svm': svm_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flu_predict(x_test):\n",
    "    weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "    weighted_logistic.fit(x, y)\n",
    "    y_pred = weighted_logistic.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1533, 1)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape y predicted values\n",
    "y_pred = flu_predict(x_testing) \n",
    "y_pred = y_pred.reshape(-1,1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1533, 1)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape ID column\n",
    "data_test_id = data_test_id.as_matrix().reshape(-1,1)\n",
    "data_test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate ID and y predicted together\n",
    "data_test_full = np.concatenate([data_test_id, y_pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save dataset as csv\n",
    "np.savetxt(\n",
    "    'flu.txt',              # file name\n",
    "    data_test_full,         # array to save\n",
    "    fmt='%.0f',             # formatting, 2 digits in this case\n",
    "    delimiter=',',          # column delimiter\n",
    "    newline='\\n',           # new line character\n",
    "    header = (\"index,label\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Diagnosing Strains of the Semian Flu\n",
    "\n",
    "From a public health perspective, we want to balance the cost of vaccinations, early interventions and the cost of treating flu complications of unvaccinated people. \n",
    "\n",
    "There are two different strains of the flu: strain 1 has a cheaper early intervention as well as a cheaper treatment for flu complications, but patients with strain 1 has a higher rate of developing complications if treated with the wrong intervention. Strain 2 has a more expensive early intervention as well as a more costly treatment for flu complications, but patients with strain 2 has a lower rate of developing complications if treated with the wrong intervention. With no intervention, flu patients develop complications at the same rate regardless of the strain. \n",
    "\n",
    "**Your task:** build a model to predict if a given patient has the flu and identify the flu strain. The state government of MA will use your model to inform public health policies: we will vaccinate people you've identified as healthy and apply corresponding interventions to patients with different strains of the flu. We have provided you with a function to compute the total expected cost of this policy decision that takes into account the cost of the vaccine, the interventions and the cost of the treatments for flu complications resulting from misdiagnosing patients. Your goal is to make sure your model produces a public health policy with the lowest associated expected cost.\n",
    "\n",
    "**The deliverable:** a function called `flu_predict` which satisfies:\n",
    "\n",
    "- input: `x_test`, a set of medical predictors for a group of patients\n",
    "- output: `y_pred`, a set of labels, one for each patient; 1 for healthy, 2 for infected with strain 1, and 3 for infected with strain 2.\n",
    "\n",
    "The MA state government will use your model to diagnose sets of future patients (held by us). You can expect that there will be an increase in the number of flu patients in any groups of patients in the future.\n",
    "\n",
    "We provide you with some benchmarks for comparison.\n",
    "\n",
    "**Three Baseline Models:** \n",
    "- expected cost on observed data: \\$6,818,206.0, \\$7,035,735.0, \\$8,297,197.5\n",
    "- time to build: 1 min\n",
    "\n",
    "**Reasonable Model:** \n",
    "- expected cost on observed data: $6,300,000\n",
    "- time to build: 20 min\n",
    "\n",
    "**Grading:**\n",
    "Your grade will be based on:\n",
    "1. your model's ability to out-perform our benchmarks\n",
    "2. your ability to carefully and thoroughly follow the data science pipeline (see lecture slides for definition)\n",
    "3. the extend to which all choices are reasonable and defensible by methods you have learned in this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict not only the presence of the flu but also the strain of flu (strain 1 or strain 2). We can measure effectivness using the cost function, which outputs the cost. I applied the same cleaning methods from part 1 to the dataset and split into testing and training sets.\n",
    "\n",
    "I test 4 random models:\n",
    "1. Assume all 1 - healthy\n",
    "2. Assume all 2 - infected with strain 1\n",
    "3. Assume all 3 - infected with strain 2\n",
    "4. (Bonus) Randomly assign a value - either 1, 2, or 3 all with equal likelihood \n",
    "\n",
    "The cost is much lower for all 1s (all healthy) than for assuming all 2/3s or random. This is because we need to consider the drastically increased number of false positive and incorect diagnoses. \n",
    "\n",
    "I tuned random forests for the optimal depth to establish a baseline. The next step is to test on 10 different models.\n",
    "1. KNN\n",
    "2. Unweighted logistic regression\n",
    "3. Unweighted logistic quadratic regression\n",
    "4. Weighted logistic regression\n",
    "5. Weighted quad logistic regression\n",
    "6. LDA\n",
    "7. QDA\n",
    "8. Decision Tree\n",
    "9. Random Forest\n",
    "10. SVM\n",
    "\n",
    "LDA produced the lowest costs out of all models. However, LDA assumes normally distributed predictor values, which is not the case with our data. Roughly half of our data consists of categorical variables transformed through one-hot and is therefore not guassian distributed. Thus, I am more inclined to believe that the lower costs are attributed to chance and cannot be reliablely replicated. Random forests and decision trees have very similiar costs ($6.3 million). However, random forests are generally more accurate than decision trees, especially after tuning, so I decided to proceed with this model. Random forests allows for the most accurate divisions and combines multiple trees, which allow us to reduce variance through averaging out multiple trials. It also has fairly high predictive accuracy among all three classes.\n",
    "\n",
    "The next step is to tune the depth of the random forest according to costs. By finding the minimum of the plot, we have the depth of the tree that results in the classification with the lowest cost. I used the tuned random forest to produce my final estimates (costs of $5907996.0).\n",
    "\n",
    "Finally, I concatenated IDs and final predictions together to export into CSV format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------  cost\n",
    "# A function that computes the expected cost of the public healthy policy based on the \n",
    "# classifications generated by your model\n",
    "# Input: \n",
    "#      y_true (true class labels: 1, 2, 3)\n",
    "#      y_pred (predicted class labels: 1, 2, 3)\n",
    "# Returns: \n",
    "#      total_cost (expected total cost)\n",
    "\n",
    "def cost(y_true, y_pred):\n",
    "    cost_of_treatment_1 = 29500\n",
    "    cost_of_treatment_2 = 45000\n",
    "    cost_of_intervention_1 = 4150\n",
    "    cost_of_intervention_2 = 4250\n",
    "    cost_of_vaccine = 15\n",
    "    \n",
    "    prob_complications_untreated = 0.65\n",
    "    prob_complications_1 = 0.30\n",
    "    prob_complications_2 = 0.15\n",
    "    \n",
    "    trials = 1000\n",
    "    \n",
    "    intervention_cost = cost_of_intervention_1 * len(y_pred[y_pred==2]) + cost_of_intervention_2 * len(y_pred[y_pred==3])\n",
    "\n",
    "    vaccine_cost = cost_of_vaccine * len(y_pred[y_pred==1])\n",
    "    \n",
    "    false_neg_1 = ((y_true == 2) & (y_pred == 3)).sum()\n",
    "    false_neg_2 = ((y_true == 3) & (y_pred == 2)).sum()\n",
    "    \n",
    "    untreated_1 = ((y_true == 2) & (y_pred == 1)).sum()    \n",
    "    untreated_2 = ((y_true == 3) & (y_pred == 1)).sum()\n",
    "    \n",
    "    false_neg_1_cost = np.random.binomial(1, prob_complications_1, (false_neg_1, trials)) * cost_of_treatment_1\n",
    "    false_neg_2_cost = np.random.binomial(1, prob_complications_2, (false_neg_2, trials)) * cost_of_treatment_2\n",
    "    untreated_1_cost = np.random.binomial(1, prob_complications_untreated, (untreated_1, trials)) * cost_of_treatment_1\n",
    "    untreated_2_cost = np.random.binomial(1, prob_complications_untreated, (untreated_2, trials)) * cost_of_treatment_2\n",
    "    \n",
    "    false_neg_1_cost = false_neg_1_cost.sum(axis=0)\n",
    "    expected_false_neg_1_cost = false_neg_1_cost.mean()\n",
    "    \n",
    "    false_neg_2_cost = false_neg_2_cost.sum(axis=0)\n",
    "    expected_false_neg_2_cost = false_neg_2_cost.mean()\n",
    "    \n",
    "    untreated_1_cost = untreated_1_cost.sum(axis=0)\n",
    "    expected_untreated_1_cost = untreated_1_cost.mean()\n",
    "    \n",
    "    untreated_2_cost = untreated_2_cost.sum(axis=0)\n",
    "    expected_untreated_2_cost = untreated_2_cost.mean()\n",
    "    \n",
    "    total_cost = vaccine_cost + intervention_cost + expected_false_neg_1_cost + expected_false_neg_2_cost + expected_untreated_1_cost + expected_untreated_2_cost\n",
    "    \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>HomeOwn</th>\n",
       "      <th>Work</th>\n",
       "      <th>...</th>\n",
       "      <th>PhysActive</th>\n",
       "      <th>Alcohol12PlusYr</th>\n",
       "      <th>AlcoholYear</th>\n",
       "      <th>Smoke100</th>\n",
       "      <th>Smoke100n</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SameSex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Race1  Education  MaritalStatus  HHIncomeMid  Poverty  \\\n",
       "0       1   4.0      4          4              2      22500.0     1.07   \n",
       "1       1  60.0      5          3              2      17500.0     1.03   \n",
       "2       1  38.0      5          4              2      22500.0     1.15   \n",
       "3       1   8.0      5          4              2      70000.0     3.55   \n",
       "4       0  59.0      4          0              5      22500.0     1.37   \n",
       "\n",
       "   HomeRooms  HomeOwn  Work   ...     PhysActive  Alcohol12PlusYr  \\\n",
       "0        9.0        1     2   ...              1                1   \n",
       "1        5.0        1     2   ...              0                1   \n",
       "2        6.0        1     2   ...              0                0   \n",
       "3        5.0        1     2   ...              1                1   \n",
       "4        4.0        2     1   ...              0                1   \n",
       "\n",
       "   AlcoholYear  Smoke100  Smoke100n  HardDrugs  SexEver  SexAge  \\\n",
       "0         24.0         0          0          0        1    17.0   \n",
       "1         36.0         1          1          0        1    20.0   \n",
       "2          0.0         0          0          0        1    23.0   \n",
       "3         24.0         0          0          0        1    17.0   \n",
       "4         24.0         0          0          0        1    17.0   \n",
       "\n",
       "   SexNumPartnLife  SameSex  \n",
       "0              5.0        0  \n",
       "1              1.0        0  \n",
       "2              1.0        0  \n",
       "3              5.0        0  \n",
       "4              5.0        0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate out x and y values\n",
    "x = data_train.values[:, :-2]\n",
    "y = data_train.values[:, -1]\n",
    "\n",
    "# Apply one hot endcoing\n",
    "encoder = preprocessing.OneHotEncoder(categorical_features=categorical[:-2], sparse=False)  # Last value in mask is y\n",
    "x = encoder.fit_transform(x)\n",
    "\n",
    "x_testing = data_test.values\n",
    "encoder = preprocessing.OneHotEncoder(categorical_features=categorical, sparse=False)  # Last value in mask is y\n",
    "x_testing = encoder.fit_transform(x_testing)\n",
    "data_test.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into testing and training sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# score function that plugs values into cost function\n",
    "score = lambda model, x_test, y_test: pd.Series([cost(y_test, model.predict(x_test)),\n",
    "                                                 model.score(x_test[y_test==1], y_test[y_test==1]),\n",
    "                                                 model.score(x_test[y_test==2], y_test[y_test==2]),\n",
    "                                                 model.score(x_test[y_test==3], y_test[y_test==3])], \n",
    "                                                 index=['overall cost', 'class 1', 'class 2', 'class 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicts all class 1\n",
    "class One_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.array([1] * len(x))\n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "    \n",
    "#A model that labels everything 2\n",
    "class Two_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.array([2] * len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "    \n",
    "# A model that labels everything 3\n",
    "class Three_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.array([3] * len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "#A model that randomly labels things\n",
    "class Random_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.random.randint(1, 4, len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run all of our models and score to obtain costs\n",
    "one_model = One_model()\n",
    "one_model_scores = score(one_model, x, y)\n",
    "\n",
    "two_model = Two_model()\n",
    "two_model_scores = score(two_model, x, y)\n",
    "\n",
    "three_model = Three_model()\n",
    "three_model_scores = score(three_model, x, y)\n",
    "\n",
    "random_model = Random_model()\n",
    "random_model_scores = score(random_model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one model</th>\n",
       "      <th>random model</th>\n",
       "      <th>three model</th>\n",
       "      <th>two model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall cost</th>\n",
       "      <td>6858961.0</td>\n",
       "      <td>1.771844e+07</td>\n",
       "      <td>24314745.5</td>\n",
       "      <td>22329350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.375203e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.480176e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.734940e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              one model  random model  three model   two model\n",
       "overall cost  6858961.0  1.771844e+07   24314745.5  22329350.0\n",
       "class 1             1.0  3.375203e-01          0.0         0.0\n",
       "class 2             0.0  3.480176e-01          0.0         1.0\n",
       "class 3             0.0  3.734940e-01          1.0         0.0"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cost Dataframe\n",
    "score_df = pd.DataFrame({'random model': random_model_scores,\n",
    "                         'one model': one_model_scores,\n",
    "                         'two model': two_model_scores,\n",
    "                         'three model': three_model_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimize accuracy by comparing predictors through a grid search\n",
    "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    best = gs.best_estimator_\n",
    "    return best\n",
    "\n",
    "# find best parameters by optimizing parameters before finding accuracy   \n",
    "def do_classify(clf, parameters, reuse_split=None, score_func=None, n_folds=5, n_jobs=1):\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, x_train, y_train, n_jobs=n_jobs, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(x_train, y_train)\n",
    "    \n",
    "    # calculate training and testing accuracy to print\n",
    "    training_accuracy = clf.score(x_train, y_train)\n",
    "    test_accuracy = clf.score(x_test, y_test)\n",
    "    print \"############# based on optimization ################\"\n",
    "    print \"Accuracy on training data: %f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %f\" % (test_accuracy)\n",
    "    print confusion_matrix(y_test, clf.predict(x_test))\n",
    "    print \"########################################################\"\n",
    "    return clf, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.940419\n",
      "Accuracy on test data:     0.941550\n",
      "[[2964    0    0]\n",
      " [ 138    0    0]\n",
      " [  46    0    0]]\n",
      "########################################################\n",
      "Number of Trees before Optimization:  10\n",
      "Depth before Optimization:  None\n"
     ]
    }
   ],
   "source": [
    "# initalize random forest classifer\n",
    "clfForest = RandomForestClassifier(oob_score=True, max_features = 'auto')\n",
    "\n",
    "# FIT THE TREE \n",
    "clf=clfForest.fit(x_train[1:100], y_train[1:100])\n",
    "\n",
    "# calculate training and testing accuracy to print\n",
    "training_accuracy = clfForest.score(x_train, y_train)\n",
    "test_accuracy = clfForest.score(x_test, y_test)\n",
    "print \"############# based on standard predict ################\"\n",
    "print \"Accuracy on training data: %f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %f\" % (test_accuracy)\n",
    "print confusion_matrix(y_test, clf.predict(x_test))\n",
    "print \"########################################################\"\n",
    "\n",
    "# print parameters selected or default\n",
    "print 'Number of Trees before Optimization: ', clfForest.n_estimators\n",
    "print 'Depth before Optimization: ', clfForest.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on optimization ################\n",
      "Accuracy on training data: 0.953289\n",
      "Accuracy on test data:     0.941550\n",
      "[[2963    1    0]\n",
      " [ 135    1    2]\n",
      " [  46    0    0]]\n",
      "########################################################\n",
      "Number of trees:  18\n",
      "Optimized Tree Depth:  7\n"
     ]
    }
   ],
   "source": [
    "# test parameters: the number of trees, depth of each tree\n",
    "parameters = {\"n_estimators\": range(1,20), \"max_depth\": range(1,10)}\n",
    "\n",
    "clfForest, x_train, y_train, x_test, y_test = do_classify(clfForest, parameters, \n",
    "                                                       n_jobs = 4)\n",
    "\n",
    "# print optimized parameters selected\n",
    "print 'Number of trees: ', clfForest.n_estimators\n",
    "print 'Optimized Tree Depth: ', clfForest.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNN(n_neighbors=knn_best_depth)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_cost = score(knn, x, y)\n",
    "\n",
    "#Unweighted logistic regression\n",
    "unweighted_logistic = LogisticRegression()\n",
    "unweighted_logistic.fit(x_train, y_train)\n",
    "unweighted_log_cost = score(unweighted_logistic, x, y)\n",
    "\n",
    "#Unweighted logistic quadratic regression\n",
    "unweighted_logistic_poly = LogisticRegression()\n",
    "\n",
    "#Expand our predictor array with quadratic terms\n",
    "quad_features = preprocessing.PolynomialFeatures(degree = 2)\n",
    "x_expanded_train = quad_features.fit_transform(x_train)\n",
    "x_expanded_test = quad_features.fit_transform(x)\n",
    "\n",
    "unweighted_logistic_poly.fit(x_expanded_train, y_train)\n",
    "unweighted_log_poly_cost = score(unweighted_logistic_poly, x_expanded_test, y)\n",
    "\n",
    "#Weighted logistic regression\n",
    "weighted_logistic = LogisticRegression(class_weight='balanced', C = logreg_best_depth)\n",
    "weighted_logistic.fit(x_train, y_train)\n",
    "weighted_log_cost = score(weighted_logistic, x, y)\n",
    "\n",
    "#Weighted quad logistic regression\n",
    "weighted_logistic_poly = LogisticRegression(class_weight='balanced')\n",
    "#Expand our predictor array with quadratic terms\n",
    "quad_features = preprocessing.PolynomialFeatures(degree = 2)\n",
    "x_expanded_train = quad_features.fit_transform(x_train)\n",
    "x_expanded_test = quad_features.fit_transform(x)\n",
    "\n",
    "weighted_logistic_poly.fit(x_expanded_train, y_train)\n",
    "weighted_log_poly_cost = score(weighted_logistic_poly, x_expanded_test, y)\n",
    "\n",
    "#LDA\n",
    "lda = LDA()\n",
    "lda.fit(x_train, y_train)\n",
    "lda_cost = score(lda, x, y)\n",
    "\n",
    "#QDA\n",
    "qda = QDA()\n",
    "qda.fit(x_train, y_train)\n",
    "qda_cost = score(qda, x, y)\n",
    "\n",
    "#Decision Tree\n",
    "tree = DecisionTree(max_depth=tree_best_depth)\n",
    "tree.fit(x_train, y_train)\n",
    "tree_cost = score(tree, x, y)\n",
    "\n",
    "#Random Forest\n",
    "clfForest.fit(x_train, y_train)\n",
    "rf_cost = score(clfForest, x, y)\n",
    "\n",
    "#SVM\n",
    "svm = SVC(C=svm_best_depth, kernel='linear', class_weight='balanced')\n",
    "svm.fit(x_train[1:100], y_train[1:100])\n",
    "svm_cost = score(svm, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>lda</th>\n",
       "      <th>qda</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "      <th>unweighted logistic</th>\n",
       "      <th>unweighted quad logistic</th>\n",
       "      <th>weighted logistic</th>\n",
       "      <th>weighted quad logistic</th>\n",
       "      <th>weighted svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall cost</th>\n",
       "      <td>6859791.5</td>\n",
       "      <td>6.015724e+06</td>\n",
       "      <td>7.040768e+06</td>\n",
       "      <td>6.308096e+06</td>\n",
       "      <td>6.317422e+06</td>\n",
       "      <td>6.763164e+06</td>\n",
       "      <td>6.876390e+06</td>\n",
       "      <td>6.366764e+06</td>\n",
       "      <td>6.520899e+06</td>\n",
       "      <td>8.011370e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.841977e-01</td>\n",
       "      <td>9.072123e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.979741e-01</td>\n",
       "      <td>9.979741e-01</td>\n",
       "      <td>9.987844e-01</td>\n",
       "      <td>9.629254e-01</td>\n",
       "      <td>9.673825e-01</td>\n",
       "      <td>9.371961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.726872e-02</td>\n",
       "      <td>4.449339e-01</td>\n",
       "      <td>8.810573e-02</td>\n",
       "      <td>8.370044e-02</td>\n",
       "      <td>8.810573e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.251101e-02</td>\n",
       "      <td>6.167401e-02</td>\n",
       "      <td>1.762115e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.493976e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.204819e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.614458e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.614458e-01</td>\n",
       "      <td>3.373494e-01</td>\n",
       "      <td>1.204819e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    knn           lda           qda            rf  \\\n",
       "overall cost  6859791.5  6.015724e+06  7.040768e+06  6.308096e+06   \n",
       "class 1             1.0  9.841977e-01  9.072123e-01  1.000000e+00   \n",
       "class 2             0.0  5.726872e-02  4.449339e-01  8.810573e-02   \n",
       "class 3             0.0  3.493976e-01  0.000000e+00  1.204819e-01   \n",
       "\n",
       "                      tree  unweighted logistic  unweighted quad logistic  \\\n",
       "overall cost  6.317422e+06         6.763164e+06              6.876390e+06   \n",
       "class 1       9.979741e-01         9.979741e-01              9.987844e-01   \n",
       "class 2       8.370044e-02         8.810573e-03              0.000000e+00   \n",
       "class 3       0.000000e+00         3.614458e-02              0.000000e+00   \n",
       "\n",
       "              weighted logistic  weighted quad logistic  weighted svm  \n",
       "overall cost       6.366764e+06            6.520899e+06  8.011370e+06  \n",
       "class 1            9.629254e-01            9.673825e-01  9.371961e-01  \n",
       "class 2            9.251101e-02            6.167401e-02  1.762115e-02  \n",
       "class 3            3.614458e-01            3.373494e-01  1.204819e-02  "
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({'knn': knn_cost, \n",
    "                         'unweighted logistic': unweighted_log_cost,\n",
    "                         'unweighted quad logistic': unweighted_log_poly_cost,\n",
    "                         'weighted logistic': weighted_log_cost,\n",
    "                         'weighted quad logistic': weighted_log_poly_cost,\n",
    "                         'lda': lda_cost,\n",
    "                         'qda': qda_cost,\n",
    "                         'tree': tree_cost,\n",
    "                         'rf': rf_cost,\n",
    "                         'weighted svm': svm_cost})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEZCAYAAACjPJNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwQXHcRzHKQouOI7jOE5R+H9KSmQuLaHF1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c0cf690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tune tree for optimal depth\n",
    "depths = range(1, 20)\n",
    "kf = KFold(len(x_train), n_folds=5)\n",
    "cost_array = []\n",
    "\n",
    "for depth in depths:\n",
    "    validation_cost = []\n",
    "    # use CV to reduce variance\n",
    "    for train_index, test_index in kf:\n",
    "        x_validate_train, x_validate_test = x_train[train_index], x_train[test_index]\n",
    "        y_validate_train, y_validate_test = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        clfForest.fit(x_train, y_train)\n",
    "        y_pred = clfForest.predict(x_validate_test)\n",
    "        validation_cost.append(cost(y_validate_test, y_pred))\n",
    "        \n",
    "    cost_array.append(np.mean(validation_cost))\n",
    "\n",
    "# determine optimal tree depth and accuracy\n",
    "best_depth = np.argmin(cost_array) + 1\n",
    "min_cost = np.amin(cost_array)\n",
    "\n",
    "# plot and label axes\n",
    "plt.plot(depths, cost_array)\n",
    "plt.title(\"Cost for Various Depths in Random Forests\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Cost\")\n",
    "\n",
    "print 'Best depth: {}'.format(best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# produce deliverable function flu_preidct\n",
    "def flu_predict(x_test):\n",
    "    tree = DecisionTree(max_depth = best_depth)\n",
    "    tree.fit(x, y)\n",
    "    y_pred = tree.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Cost after Tuning:  5907996.0\n"
     ]
    }
   ],
   "source": [
    "# prediction to find new cost metric\n",
    "final_cost = cost(y, flu_predict(x))\n",
    "print 'Final Cost after Tuning: ', final_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate y_pred on full testing set\n",
    "y_pred = flu_predict(x_testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1533, 1)"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape y_pred into column vector\n",
    "y_pred = y_pred.reshape(-1,1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate id and y_pred together\n",
    "data_test_full_2 = np.concatenate([data_test_id, y_pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save results as a csv\n",
    "np.savetxt(\n",
    "    'flu_part_2.txt',           # file name\n",
    "    data_test_full_2,                # array to save\n",
    "    fmt='%.0f',             # formatting, 2 digits in this case\n",
    "    delimiter=',',          # column delimiter\n",
    "    newline='\\n',           # new line character\n",
    "    header = (\"index,label\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
